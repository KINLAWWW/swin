{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from strokes import StrokePatientsMIDataset, StrokePatientsMIProcessedDataset\n",
    "from strokesdict import STROKEPATIENTSMI_LOCATION_DICT\n",
    "from torcheeg.transforms import Select,BandSignal,Compose\n",
    "from to import ToGrid, ToTensor\n",
    "from downsample import SetSamplingRate\n",
    "from baseline import BaselineCorrection\n",
    "\n",
    "dataset = StrokePatientsMIDataset(root_path='./subdataset',\n",
    "                                  io_path='.torcheeg/datasets_1745478591849_L5nX8',\n",
    "                        chunk_size=500,  # 1 second\n",
    "                        overlap = 250,\n",
    "                        offline_transform=Compose(\n",
    "                                [BaselineCorrection(),\n",
    "                                SetSamplingRate(origin_sampling_rate=500,target_sampling_rate=128),\n",
    "                                BandSignal(sampling_rate=128,band_dict={'frequency_range':[8,40]})\n",
    "                                ]),\n",
    "                        online_transform=Compose(\n",
    "                                [ToGrid(STROKEPATIENTSMI_LOCATION_DICT),ToTensor()]),\n",
    "                        label_transform=Select('label'),\n",
    "                        num_worker=8\n",
    ")\n",
    "print(dataset[0][0].shape) #EEG shape:torch.Size([1, 128, 9, 9])\n",
    "print(dataset[0][1])  # label (int)\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eegswintransformer import SwinTransformer\n",
    "\n",
    "HYPERPARAMETERS = {\n",
    "    \"seed\": 42,\n",
    "    \"batch_size\": 16,\n",
    "    \"lr\": 1e-4,\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"num_epochs\": 50,\n",
    "}\n",
    "from torcheeg.model_selection import KFoldPerSubjectGroupbyTrial\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from torch.utils.data import DataLoader\n",
    "from classifier import ClassifierTrainer\n",
    "\n",
    "k_fold = KFoldPerSubjectGroupbyTrial(\n",
    "    n_splits=4,\n",
    "    shuffle=True,\n",
    "    # split_path='.torcheeg/model_selection_1741918660674_jp0WB',\n",
    "    random_state=42)\n",
    "\n",
    "training_metrics = []\n",
    "test_metrics = []\n",
    "\n",
    "for i, (training_dataset, test_dataset) in enumerate(k_fold.split(dataset)):\n",
    "    model = SwinTransformer(patch_size=(8,3,3),\n",
    "                              num_classes=2,\n",
    "                              depths=(2, 6, 4),\n",
    "                              num_heads=(3,6,8),\n",
    "                              window_size=(3,3,3),\n",
    "                              in_chans=1\n",
    "                              ) # T, W, H 同时缩小\n",
    "    trainer = ClassifierTrainer(model=model,\n",
    "                                num_classes=2,\n",
    "                                lr=HYPERPARAMETERS['lr'],\n",
    "                                weight_decay=HYPERPARAMETERS['weight_decay'],\n",
    "                                metrics=[\"accuracy\"],\n",
    "                                accelerator=\"gpu\")\n",
    "    training_loader = DataLoader(training_dataset,\n",
    "                             batch_size=HYPERPARAMETERS['batch_size'],\n",
    "                             shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset,\n",
    "                             batch_size=HYPERPARAMETERS['batch_size'],\n",
    "                             shuffle=False)\n",
    "    # 提前停止回调\n",
    "    early_stopping_callback = EarlyStopping(\n",
    "        monitor='train_loss',\n",
    "        patience=50,\n",
    "        mode='min',\n",
    "        verbose=True\n",
    "    )\n",
    "    trainer.fit(training_loader,\n",
    "                test_loader,\n",
    "                max_epochs=HYPERPARAMETERS['num_epochs'],\n",
    "                callbacks=[early_stopping_callback],\n",
    "                # enable_progress_bar=True,\n",
    "                enable_model_summary=False,\n",
    "                limit_val_batches=0.0)\n",
    "    training_result = trainer.test(training_loader,\n",
    "                                   enable_progress_bar=True,\n",
    "                                   enable_model_summary=True)[0]\n",
    "    test_result = trainer.test(test_loader,\n",
    "                               enable_progress_bar=True,\n",
    "                               enable_model_summary=True)[0]\n",
    "    training_metrics.append(training_result[\"test_accuracy\"])\n",
    "    test_metrics.append(test_result[\"test_accuracy\"])\n",
    "    \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "for i in range(0, len(test_metrics), 4):\n",
    "    print(f\"{i}\\t\"\n",
    "          f\"{np.mean(training_metrics[i:i+4]):.3f}\\t\"\n",
    "          f\"{np.std(training_metrics[i:i+4]):.3f}\\t\"\n",
    "          f\"{np.mean(test_metrics[i:i+4]):.3f}\\t\"\n",
    "          f\"{np.std(test_metrics[i:i+4]):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, score in enumerate(test_metrics):\n",
    "    print(f\"{score:.3f}\", end=\"\\t\")\n",
    "    if (i + 1) % 4 == 0:\n",
    "        print()  # Print a newline every 4 elements\n",
    "\n",
    "# Ensure the last line is printed properly if the length isn't a multiple of 4\n",
    "if len(test_metrics) % 4 != 0:\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "law",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
