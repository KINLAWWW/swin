{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from strokes import StrokePatientsMIDataset, StrokePatientsMIProcessedDataset\n",
    "from strokesdict import STROKEPATIENTSMI_LOCATION_DICT\n",
    "from torcheeg.transforms import Select,BandSignal,Compose\n",
    "from to import ToGrid, ToTensor\n",
    "from downsample import SetSamplingRate\n",
    "from baseline import BaselineCorrection\n",
    "\n",
    "dataset = StrokePatientsMIDataset(root_path='./subdataset',\n",
    "                                  io_path='.torcheeg/datasets_1745478591849_L5nX8',\n",
    "                        chunk_size=500,  # 1 second\n",
    "                        overlap = 250,\n",
    "                        offline_transform=Compose(\n",
    "                                [BaselineCorrection(),\n",
    "                                SetSamplingRate(origin_sampling_rate=500,target_sampling_rate=128),\n",
    "                                BandSignal(sampling_rate=128,band_dict={'frequency_range':[8,40]})\n",
    "                                ]),\n",
    "                        online_transform=Compose(\n",
    "                                [ToGrid(STROKEPATIENTSMI_LOCATION_DICT),ToTensor()]),\n",
    "                        label_transform=Select('label'),\n",
    "                        num_worker=8\n",
    ")\n",
    "print(dataset[0][0].shape) #EEG shape:torch.Size([1, 128, 9, 9])\n",
    "print(dataset[0][1])  # label (int)\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from swin import SwinTransformer\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# 生成一个形状为 (4,1,128,9,9) 的全1张量\n",
    "x = torch.ones(4, 1, 128, 9, 9).to(device)\n",
    "\n",
    "model = SwinTransformer(patch_size=(8,1,1),\n",
    "                        depths=(2, 2, 4),\n",
    "                        num_heads=(2,2,3),\n",
    "                        window_size=(4,3,3)\n",
    "                        ).to(device)\n",
    "\n",
    "y = model(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from swin import SwinTransformer\n",
    "\n",
    "HYPERPARAMETERS = {\n",
    "    \"seed\": 42,\n",
    "    \"batch_size\": 16,\n",
    "    \"lr\": 1e-5,\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"num_epochs\": 50,\n",
    "}\n",
    "from torcheeg.model_selection import KFoldPerSubjectGroupbyTrial\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from torch.utils.data import DataLoader\n",
    "from classifier import ClassifierTrainer\n",
    "\n",
    "k_fold = KFoldPerSubjectGroupbyTrial(\n",
    "    n_splits=4,\n",
    "    shuffle=True,\n",
    "    # split_path='.torcheeg/model_selection_1741918660674_jp0WB',\n",
    "    random_state=42)\n",
    "\n",
    "training_metrics = []\n",
    "test_metrics = []\n",
    "attn_list = []\n",
    "\n",
    "\n",
    "for i, (training_dataset, test_dataset) in enumerate(k_fold.split(dataset)):\n",
    "    model = SwinTransformer(patch_size=(8,3,3), \n",
    "                            depths=(2, 2, 2),\n",
    "                            num_heads=(2,2,3),\n",
    "                            window_size=(3,3,3)\n",
    "                            ) # T, W, H 同时缩小\n",
    "    trainer = ClassifierTrainer(model=model,\n",
    "                                num_classes=2,\n",
    "                                lr=HYPERPARAMETERS['lr'],\n",
    "                                weight_decay=HYPERPARAMETERS['weight_decay'],\n",
    "                                metrics=[\"accuracy\"],\n",
    "                                accelerator=\"gpu\")\n",
    "    training_loader = DataLoader(training_dataset,\n",
    "                             batch_size=HYPERPARAMETERS['batch_size'],\n",
    "                             shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset,\n",
    "                             batch_size=HYPERPARAMETERS['batch_size'],\n",
    "                             shuffle=False)\n",
    "    # 提前停止回调\n",
    "    early_stopping_callback = EarlyStopping(\n",
    "        monitor='train_loss',\n",
    "        patience=50,\n",
    "        mode='min',\n",
    "        verbose=True\n",
    "    )\n",
    "    trainer.fit(training_loader,\n",
    "                test_loader,\n",
    "                max_epochs=HYPERPARAMETERS['num_epochs'],\n",
    "                callbacks=[early_stopping_callback],\n",
    "                # enable_progress_bar=True,\n",
    "                enable_model_summary=False,\n",
    "                limit_val_batches=0.0)\n",
    "    training_result = trainer.test(training_loader,\n",
    "                                   enable_progress_bar=True,\n",
    "                                   enable_model_summary=True)[0]\n",
    "    test_result = trainer.test(test_loader,\n",
    "                               enable_progress_bar=True,\n",
    "                               enable_model_summary=True)[0]\n",
    "    attn_list.append(model.layers[2].blocks[0].attn.attn_scores)\n",
    "    training_metrics.append(training_result[\"test_accuracy\"])\n",
    "    test_metrics.append(test_result[\"test_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_metrics)\n",
    "avg = sum(test_metrics) / len(test_metrics)\n",
    "print(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(attn_list))\n",
    "print(attn_list[3].shape)\n",
    "# print(model.layers[0].blocks[0].attn.attn_scores)\n",
    "sample = attn_list[3]\n",
    "sample = torch.mean(sample, dim=2)\n",
    "print(sample.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = sample.masked_fill(sample < 0.0375, 0)\n",
    "# sample = torch.mean(sample, dim=1)\n",
    "print(sample[2]*1000)\n",
    "v = sample[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 归一化到 [0, 1]\n",
    "sample_min = sample[2].min()\n",
    "sample_max = sample[2].max()\n",
    "v = (sample[2] - sample_min) / (sample_max - sample_min + 1e-8)\n",
    "\n",
    "# 拉大差距\n",
    "v = v ** 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.layers[0].blocks[1].attn.attn_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = attn_list[3][0]\n",
    "print(attn.shape)\n",
    "attn = torch.mean(attn, dim=1)  # 形状变为 (16, 36, 36)\n",
    "attn = torch.mean(attn,dim=1)   # 计算所有token对一个token的平均影响力\n",
    "attn = attn.reshape(16,16,3,3)\n",
    "attn = torch.mean(attn, dim=1)  # 形状变为 (16, 36, 36)\n",
    "print(attn.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = v.reshape(3,3,3)\n",
    "v = torch.mean(v, dim=0)\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 示例注意力权重 (3,3)\n",
    "attention_weights = v\n",
    "print(attention_weights)\n",
    "\n",
    "# 画热力图\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.heatmap(attention_weights.numpy(), annot=True, cmap=\"viridis\", fmt=\".2f\",\n",
    "            xticklabels=[\"Col 1\", \"Col 2\", \"Col 3\"],\n",
    "            yticklabels=[\"Row 1\", \"Row 2\", \"Row 3\"])\n",
    "\n",
    "plt.title(\"Spatial Attention Weights\")\n",
    "plt.xlabel(\"Feature Map Width\")\n",
    "plt.ylabel(\"Feature Map Height\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/autodl-tmp/conda/envs/law/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/root/autodl-tmp/conda/envs/law/lib/python3.8/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/native/TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "from swin_CAM import SwinTransformer\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 生成一个形状为 (4,1,128,9,9) 的全1张量\n",
    "input_tensor = torch.randn(1, 1, 128, 9, 9).to(device)\n",
    "\n",
    "\n",
    "model = SwinTransformer(patch_size=(8,1,1),\n",
    "                        depths=(2, 2, 4),\n",
    "                        num_heads=(2,2,3),\n",
    "                        window_size=(4,3,3)\n",
    "                        ).to(device)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "target_layers = [model.layers[-1].blocks[-1].norm1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer output shape: torch.Size([1, 36, 1536])\n"
     ]
    }
   ],
   "source": [
    "def get_shape(module, input, output):\n",
    "    print(f\"Layer output shape: {output.shape}\")\n",
    "\n",
    "target_layer = model.layers[-1].blocks[-1].norm1\n",
    "handle = target_layer.register_forward_hook(get_shape)\n",
    "\n",
    "# 运行前向传播\n",
    "with torch.no_grad():\n",
    "    _ = model(input_tensor)  # 触发hook打印形状\n",
    "handle.remove()  # 必须移除hook防止内存泄漏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4, 3, 3)\n",
      "(1, 128, 9, 9)\n",
      "(9, 9)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pytorch_grad_cam import GradCAM\n",
    "import matplotlib.pyplot as plt\n",
    "# --- 自定义形状转换函数 ---\n",
    "def reshape_transform(tensor, original_T=128, original_H=9, original_W=9):\n",
    "    \"\"\"\n",
    "    输入: [B, N=36, C=1536] \n",
    "    输出: [B, C, H'=3, W'=3] (时间平均 + 空间对齐)\n",
    "    \"\"\"\n",
    "    B, N, C = tensor.shape\n",
    "    \n",
    "    # 1. 将36分解为4(T')×3(H')×3(W') → [B,4,3,3,C]\n",
    "    restored = tensor.view(B, 4, 3, 3, C)\n",
    "    \n",
    "    # 3. 调整为CAM需要的 [B,C,H',W']\n",
    "    return restored.permute(0, 4, 1, 2, 3)\n",
    "\n",
    "cam = LayerCAM(model=model, target_layers=target_layers, reshape_transform=reshape_transform)\n",
    "\n",
    "# 生成 CAM 热力图\n",
    "grayscale_cam = cam(input_tensor=input_tensor)\n",
    "print(grayscale_cam.shape)\n",
    "grayscale_cam = grayscale_cam[0, :]  # 取第一个样本的热图，形状：[T', H', W']\n",
    "\n",
    "# 可视化热图的某一帧（例如中间一帧）\n",
    "t_index = grayscale_cam.shape[0] // 2\n",
    "cam_frame = grayscale_cam[t_index]\n",
    "print(cam_frame.shape)\n",
    "plt.imshow(cam_frame, cmap='jet')\n",
    "plt.title(f'Grad-CAM at frame {t_index}')\n",
    "plt.colorbar()\n",
    "plt.savefig(\"gradcam_output.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/autodl-tmp/conda/envs/law/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/root/autodl-tmp/conda/envs/law/lib/python3.8/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/native/TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "from swin_CAM import SwinTransformer\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 生成一个形状为 (4,1,128,9,9) 的全1张量\n",
    "input_tensor = torch.randn(1, 1, 128, 9, 9).to(device)\n",
    "\n",
    "\n",
    "model = SwinTransformer(patch_size=(8,1,1),\n",
    "                        depths=(2, 2, 4),\n",
    "                        num_heads=(2,2,3),\n",
    "                        window_size=(4,3,3)\n",
    "                        ).to(device)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "target_layers = [model.layers[-1].blocks[-1].norm1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 128, 9, 9)\n"
     ]
    }
   ],
   "source": [
    "from pytorch_grad_cam import GradCAM\n",
    "\n",
    "class EEGSwinCAM(LayerCAM):\n",
    "    def __init__(self, model, target_layers, original_shape):\n",
    "        self.original_shape = original_shape\n",
    "        super().__init__(model, target_layers, self.reshape_transform)\n",
    "    \n",
    "    def reshape_transform(self, tensor):\n",
    "        B, N, D = tensor.shape\n",
    "     \n",
    "        patch_T = 4\n",
    "        patch_H = 3\n",
    "        patch_W = 3\n",
    "        \n",
    "        return tensor.reshape(B, patch_T, patch_H, patch_W, D).permute(0,4,1,2,3)\n",
    "\n",
    "# 使用示例\n",
    "input_tensor = torch.randn(1, 1, 128, 9, 9)\n",
    "cam = EEGSwinCAM(model, target_layers, input_tensor.shape)\n",
    "cam_map = cam(input_tensor)  # 形状 [1,4,3,3]\n",
    "print(cam_map.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/autodl-tmp/conda/envs/law/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/root/autodl-tmp/conda/envs/law/lib/python3.8/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/native/TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1536, 4, 3, 3)\n",
      "cam: (2, 4, 3, 3)\n",
      "CAM shape: (2, 3, 3)\n",
      "CAM values for sample 0:\n",
      " [[0.28417727 0.44186538 0.38192427]\n",
      " [0.09306236 0.         0.        ]\n",
      " [0.16707207 0.9999847  0.55298334]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "\n",
    "# TODO: 替换为你的 EEG Swin Transformer 模型类\n",
    "from swin_CAM import SwinTransformer  \n",
    "\n",
    "# 假设目标层输出为 (batch, 36, 1536)，即 6×6 patch，1536 维特征\n",
    "def reshape_transform(tensor, time=4, height=3, width=3):\n",
    "    # 输入形状: (B, 36, 1536)\n",
    "    B, seq_len, C = tensor.size()\n",
    "\n",
    "    result = tensor.reshape(B, time, height, width, C)\n",
    "    # result = torch.mean(result, dim=1)\n",
    "    result = result.permute(0, 4, 1, 2, 3)  # (B, C, H, W)\n",
    "    return result\n",
    "\n",
    "# 加载模型\n",
    "model = SwinTransformer(patch_size=(8,1,1),\n",
    "                        depths=(2, 2, 4),\n",
    "                        num_heads=(2,2,3),\n",
    "                        window_size=(4,3,3)\n",
    "                        )\n",
    "model.eval()\n",
    "target_layers = [model.layers[-1].blocks[-1].norm2]  # 替换为你的实际目标层\n",
    "\n",
    "# 是否使用GPU\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "\n",
    "# 示例 EEG 输入 (batch, 1, 128, 9, 9)\n",
    "eeg_input = torch.randn(2, 1, 128, 9, 9)  # 假设 batch size 为 2\n",
    "if use_cuda:\n",
    "    eeg_input = eeg_input.cuda()\n",
    "\n",
    "# 初始化 GradCAM\n",
    "cam = GradCAM(model=model, \n",
    "              target_layers=target_layers, \n",
    "              reshape_transform=reshape_transform)\n",
    "\n",
    "# 可选：设定目标类别（如果是分类问题）\n",
    "targets = None  # 或 [ClassifierOutputTarget(class_id)]\n",
    "\n",
    "# 获取灰度 CAM 输出: (batch, H, W)\n",
    "grayscale_cam = cam(input_tensor=eeg_input, targets=targets)\n",
    "\n",
    "# 输出结果\n",
    "print(\"CAM shape:\", grayscale_cam.shape)  # 应为 (batch_size, 6, 6)\n",
    "print(\"CAM values for sample 0:\\n\", grayscale_cam[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "law",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
