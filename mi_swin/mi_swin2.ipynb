{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/autodl-tmp/conda/envs/law/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[2025-01-16 16:05:35] INFO (torcheeg/MainThread) üîç | Processing EEG data. Processed EEG data has been cached to \u001b[92m.torcheeg/datasets_1737014735074_lmTAi\u001b[0m.\n",
      "[2025-01-16 16:05:35] INFO (torcheeg/MainThread) ‚è≥ | Monitoring the detailed processing of a record for debugging. The processing of other records will only be reported in percentage to keep it clean.\n",
      "[PROCESS]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 205.77it/s]\n",
      "\n",
      "[RECORD ./subdataset/sourcedata/sub-45/sub-45_task-motor-imagery_eeg.mat]: 0it [00:00, ?it/s]\u001b[A\n",
      "[RECORD ./subdataset/sourcedata/sub-45/sub-45_task-motor-imagery_eeg.mat]: 1it [00:00,  4.45it/s]\u001b[A\n",
      "[RECORD ./subdataset/sourcedata/sub-45/sub-45_task-motor-imagery_eeg.mat]: 2it [00:00,  5.78it/s]\u001b[A\n",
      "[RECORD ./subdataset/sourcedata/sub-45/sub-45_task-motor-imagery_eeg.mat]: 12it [00:00, 36.41it/s]\u001b[A\n",
      "[RECORD ./subdataset/sourcedata/sub-45/sub-45_task-motor-imagery_eeg.mat]: 22it [00:00, 56.40it/s]\u001b[A\n",
      "[RECORD ./subdataset/sourcedata/sub-45/sub-45_task-motor-imagery_eeg.mat]: 32it [00:00, 69.61it/s]\u001b[A\n",
      "[RECORD ./subdataset/sourcedata/sub-45/sub-45_task-motor-imagery_eeg.mat]: 42it [00:00, 78.81it/s]\u001b[A\n",
      "[RECORD ./subdataset/sourcedata/sub-45/sub-45_task-motor-imagery_eeg.mat]: 52it [00:00, 85.14it/s]\u001b[A\n",
      "[RECORD ./subdataset/sourcedata/sub-45/sub-45_task-motor-imagery_eeg.mat]: 63it [00:00, 89.45it/s]\u001b[A\n",
      "[RECORD ./subdataset/sourcedata/sub-45/sub-45_task-motor-imagery_eeg.mat]: 73it [00:01, 92.18it/s]\u001b[A\n",
      "[RECORD ./subdataset/sourcedata/sub-45/sub-45_task-motor-imagery_eeg.mat]: 83it [00:01, 92.82it/s]\u001b[A\n",
      "[RECORD ./subdataset/sourcedata/sub-45/sub-45_task-motor-imagery_eeg.mat]: 93it [00:01, 93.85it/s]\u001b[A\n",
      "[RECORD ./subdataset/sourcedata/sub-45/sub-45_task-motor-imagery_eeg.mat]: 103it [00:01, 95.08it/s]\u001b[A\n",
      "[RECORD ./subdataset/sourcedata/sub-45/sub-45_task-motor-imagery_eeg.mat]: 113it [00:01, 96.43it/s]\u001b[A\n",
      "[RECORD ./subdataset/sourcedata/sub-45/sub-45_task-motor-imagery_eeg.mat]: 124it [00:01, 97.05it/s]\u001b[A\n",
      "[RECORD ./subdataset/sourcedata/sub-45/sub-45_task-motor-imagery_eeg.mat]: 135it [00:01, 97.36it/s]\u001b[A\n",
      "[RECORD ./subdataset/sourcedata/sub-45/sub-45_task-motor-imagery_eeg.mat]: 145it [00:01, 97.25it/s]\u001b[A\n",
      "[RECORD ./subdataset/sourcedata/sub-45/sub-45_task-motor-imagery_eeg.mat]: 155it [00:01, 97.57it/s]\u001b[A\n",
      "[RECORD ./subdataset/sourcedata/sub-45/sub-45_task-motor-imagery_eeg.mat]: 165it [00:02, 97.95it/s]\u001b[A\n",
      "[RECORD ./subdataset/sourcedata/sub-45/sub-45_task-motor-imagery_eeg.mat]: 175it [00:02, 98.34it/s]\u001b[A\n",
      "[RECORD ./subdataset/sourcedata/sub-45/sub-45_task-motor-imagery_eeg.mat]: 186it [00:02, 101.72it/s]\u001b[A\n",
      "[RECORD ./subdataset/sourcedata/sub-45/sub-45_task-motor-imagery_eeg.mat]: 197it [00:02, 100.60it/s]\u001b[A\n",
      "                                                                                                    \u001b[A[2025-01-16 16:05:39] INFO (torcheeg/MainThread) ‚úÖ | All processed EEG data has been cached to .torcheeg/datasets_1737014735074_lmTAi.\n",
      "[2025-01-16 16:05:39] INFO (torcheeg/MainThread) üòä | Please set \u001b[92mio_path\u001b[0m to \u001b[92m.torcheeg/datasets_1737014735074_lmTAi\u001b[0m for the next run, to directly read from the cache if you wish to skip the data processing step.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 30, 484])\n",
      "0\n",
      "320\n"
     ]
    }
   ],
   "source": [
    "from strokesinit import StrokePatientsMIProcessedDataset, StrokePatientsMIDataset\n",
    "import scipy\n",
    "from strokesdict import STROKEPATIENTSMI_LOCATION_DICT\n",
    "from torcheeg.transforms import Select,BandSignal,Compose,Lambda,ToTensor,BandDifferentialEntropy,Resize\n",
    "from to import ToGrid\n",
    "from typing import Callable, Dict, Union, List\n",
    "import numpy as np\n",
    "import soxr\n",
    "from downsample import SetSamplingRate\n",
    "from baseline import BaselineCorrection\n",
    "from base_transform import EEGTransform\n",
    "    \n",
    "\n",
    "dataset = StrokePatientsMIDataset(root_path='./subdataset',\n",
    "                                #   io_path='.torcheeg/datasets_1735798885866_IhPTv',\n",
    "                        chunk_size=500,  # 1 second\n",
    "                        overlap = 0,\n",
    "                        offline_transform=Compose(\n",
    "                                [BaselineCorrection(),SetSamplingRate(500,484),\n",
    "                                BandSignal(sampling_rate=484,band_dict={'frequency_range':[8,40]})]),\n",
    "                        online_transform=Compose(\n",
    "                                [ToTensor()]),\n",
    "                \n",
    "                        label_transform=Select('label'),\n",
    "                        num_worker=8\n",
    ")\n",
    "print(dataset[0][0].shape) #EEG shape(1,30,500)\n",
    "print(dataset[0][1])  # label (int)\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HYPERPARAMETERS = {\n",
    "    \"seed\": 42,\n",
    "    \"batch_size\": 32,\n",
    "    \"lr\": 1e-4,\n",
    "    \"weight_decay\": 0,\n",
    "    \"num_epochs\": 50,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eca import ECA\n",
    "from model import SwinTransformer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ECASwinTransformerModel(nn.Module):\n",
    "    def __init__(self, num_channels):\n",
    "        super(ECASwinTransformerModel, self).__init__()\n",
    "        self.eca = ECA(input_size=484,num_attention_heads=1,hidden_size=484,hidden_dropout_prob=0.5)\n",
    "        self.swin_transformer = SwinTransformer(\n",
    "                                                in_chans=30,\n",
    "                                                num_classes=2,\n",
    "                                                embed_dim=192,\n",
    "                                                depths=(2, 2, 18, 2),\n",
    "                                                num_heads=(6, 12, 24, 48)\n",
    "                                                )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0),30,484)\n",
    "        x = self.eca(x)\n",
    "        x = x.view(x.size(0),30,22,22)\n",
    "        x = self.swin_transformer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def delete_folder_if_exists(target_folder_name):\n",
    "    # Ëé∑ÂèñÁà∂Êñá‰ª∂Â§π‰∏≠ÁöÑÊâÄÊúâÂÜÖÂÆπ\n",
    "    parent_folder = os.getcwd()\n",
    "    for folder_name in os.listdir(parent_folder):\n",
    "        folder_path = os.path.join(parent_folder, folder_name)\n",
    "\n",
    "        # Ê£ÄÊü•ÊòØÂê¶ÊòØÊñá‰ª∂Â§πÂπ∂‰∏îÂêçÁß∞ÊòØÂê¶ÂåπÈÖç\n",
    "        if os.path.isdir(folder_path) and folder_name == target_folder_name:\n",
    "            try:\n",
    "                # Âà†Èô§ÁõÆÊ†áÊñá‰ª∂Â§π\n",
    "                shutil.rmtree(folder_path)\n",
    "                print(f\"Â∑≤Âà†Èô§Êñá‰ª∂Â§π: {folder_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Âà†Èô§Êñá‰ª∂Â§π {folder_path} Êó∂Âá∫Èîô: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torcheeg.model_selection import KFoldPerSubject\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from torch.utils.data import DataLoader\n",
    "from model import SwinTransformer\n",
    "from torcheeg.trainers import ClassifierTrainer\n",
    "\n",
    "k_fold = KFoldPerSubject(\n",
    "    n_splits=5,\n",
    "    shuffle=True,\n",
    "    random_state=42)\n",
    "\n",
    "training_metrics = []\n",
    "test_metrics = []\n",
    "\n",
    "for i, (training_dataset, test_dataset) in enumerate(k_fold.split(dataset)):\n",
    "    delete_folder_if_exists(target_folder_name='lightning_logs')\n",
    "    model = ECASwinTransformerModel(num_channels=30)\n",
    "    trainer = ClassifierTrainer(model=model,\n",
    "                                num_classes=2,\n",
    "                                lr=HYPERPARAMETERS['lr'],\n",
    "                                weight_decay=HYPERPARAMETERS['weight_decay'],\n",
    "                                metrics=[\"accuracy\"],\n",
    "                                accelerator=\"gpu\")\n",
    "    \n",
    "    training_loader = DataLoader(training_dataset,\n",
    "                             batch_size=HYPERPARAMETERS['batch_size'],\n",
    "                             shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset,\n",
    "                             batch_size=HYPERPARAMETERS['batch_size'],\n",
    "                             shuffle=False)\n",
    "    # ÊèêÂâçÂÅúÊ≠¢ÂõûË∞É\n",
    "    early_stopping_callback = EarlyStopping(\n",
    "        monitor='train_loss',\n",
    "        patience=8, \n",
    "        mode='min',\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    trainer.fit(training_loader,\n",
    "                test_loader,\n",
    "                max_epochs=HYPERPARAMETERS['num_epochs'],\n",
    "                callbacks=[early_stopping_callback],\n",
    "                enable_progress_bar=True,\n",
    "                enable_model_summary=False,\n",
    "                limit_val_batches=0.0)\n",
    "    # training_result = trainer.test(training_loader,\n",
    "    #                                enable_progress_bar=True,\n",
    "    #                                enable_model_summary=True)[0]\n",
    "    test_result = trainer.test(test_loader,\n",
    "                               enable_progress_bar=True,\n",
    "                               enable_model_summary=True)[0]\n",
    "    # training_metrics.append(training_result[\"test_accuracy\"])\n",
    "    test_metrics.append(test_result[\"test_accuracy\"])\n",
    "     \n",
    "print({\n",
    "    # \"training_metric_avg\": np.mean(training_metrics),\n",
    "    # \"training_metric_std\": np.std(training_metrics),\n",
    "    \"test_metric_avg\": np.mean(test_metrics),\n",
    "    \"test_metric_std\": np.std(test_metrics)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.78125\n",
      "1 0.53125\n",
      "2 0.78125\n",
      "3 0.71875\n",
      "4 0.75\n",
      "5 0.625\n",
      "6 0.59375\n",
      "7 0.40625\n",
      "8 0.4375\n",
      "9 0.6875\n"
     ]
    }
   ],
   "source": [
    "for i, score in enumerate(test_metrics):\n",
    "    print(i,score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'len': 10, 'test_metric_avg': 0.63125, 'test_metric_std': 0.13020416659999787}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print({\n",
    "    # \"training_metric_avg\": np.mean(training_metrics),\n",
    "    # \"training_metric_std\": np.std(training_metrics),\n",
    "    \"len\": len(test_metrics),\n",
    "    \"test_metric_avg\": np.mean(test_metrics),\n",
    "    \"test_metric_std\": np.std(test_metrics)\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "law",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
