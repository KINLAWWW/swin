{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/autodl-tmp/conda/envs/swin_law/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.4.1+cu121\n",
      "Torchvision version: 0.13.1+cu113\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"Torchvision version:\", torchvision.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/autodl-tmp/conda/envs/swin_law/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SwinTransformer(\n",
      "  (features): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(3, 512, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (1): Permute()\n",
      "      (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): SwinTransformerBlock(\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttention(\n",
      "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): SwinTransformerBlock(\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttention(\n",
      "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.009090909090909092, mode=row)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): PatchMerging(\n",
      "      (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
      "      (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): SwinTransformerBlock(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.018181818181818184, mode=row)\n",
      "        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): SwinTransformerBlock(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.02727272727272728, mode=row)\n",
      "        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): PatchMerging(\n",
      "      (reduction): Linear(in_features=4096, out_features=2048, bias=False)\n",
      "      (norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): SwinTransformerBlock(\n",
      "        (norm1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttention(\n",
      "          (qkv): Linear(in_features=2048, out_features=6144, bias=True)\n",
      "          (proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.03636363636363637, mode=row)\n",
      "        (norm2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=2048, out_features=8192, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=8192, out_features=2048, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): SwinTransformerBlock(\n",
      "        (norm1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttention(\n",
      "          (qkv): Linear(in_features=2048, out_features=6144, bias=True)\n",
      "          (proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.045454545454545456, mode=row)\n",
      "        (norm2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=2048, out_features=8192, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=8192, out_features=2048, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): SwinTransformerBlock(\n",
      "        (norm1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttention(\n",
      "          (qkv): Linear(in_features=2048, out_features=6144, bias=True)\n",
      "          (proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.05454545454545456, mode=row)\n",
      "        (norm2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=2048, out_features=8192, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=8192, out_features=2048, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): SwinTransformerBlock(\n",
      "        (norm1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttention(\n",
      "          (qkv): Linear(in_features=2048, out_features=6144, bias=True)\n",
      "          (proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.06363636363636364, mode=row)\n",
      "        (norm2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=2048, out_features=8192, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=8192, out_features=2048, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): SwinTransformerBlock(\n",
      "        (norm1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttention(\n",
      "          (qkv): Linear(in_features=2048, out_features=6144, bias=True)\n",
      "          (proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.07272727272727274, mode=row)\n",
      "        (norm2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=2048, out_features=8192, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=8192, out_features=2048, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): SwinTransformerBlock(\n",
      "        (norm1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttention(\n",
      "          (qkv): Linear(in_features=2048, out_features=6144, bias=True)\n",
      "          (proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.08181818181818182, mode=row)\n",
      "        (norm2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=2048, out_features=8192, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=8192, out_features=2048, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (6): PatchMerging(\n",
      "      (reduction): Linear(in_features=8192, out_features=4096, bias=False)\n",
      "      (norm): LayerNorm((8192,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (7): Sequential(\n",
      "      (0): SwinTransformerBlock(\n",
      "        (norm1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttention(\n",
      "          (qkv): Linear(in_features=4096, out_features=12288, bias=True)\n",
      "          (proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.09090909090909091, mode=row)\n",
      "        (norm2): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): SwinTransformerBlock(\n",
      "        (norm1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttention(\n",
      "          (qkv): Linear(in_features=4096, out_features=12288, bias=True)\n",
      "          (proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
      "        (norm2): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "  (head): Linear(in_features=4096, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.models import swin_t,  SwinTransformer\n",
    "\n",
    "# 配置模型参数\n",
    "patch_size = [2, 2]\n",
    "embed_dim = 512\n",
    "depths = [2, 2, 6, 2]\n",
    "num_heads = [3, 6, 12, 24]\n",
    "window_size = [3, 3]\n",
    "stochastic_depth_prob = 0.1\n",
    "num_classes = 2  # 分类类别数量\n",
    "\n",
    "# 初始化模型\n",
    "model = SwinTransformer(\n",
    "    patch_size=patch_size,\n",
    "    embed_dim=embed_dim,\n",
    "    depths=depths,\n",
    "    num_heads=num_heads,\n",
    "    window_size=window_size,\n",
    "    stochastic_depth_prob=stochastic_depth_prob,\n",
    "    num_classes=num_classes,\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/autodl-tmp/conda/envs/swin_law/lib/python3.8/site-packages/torch/functional.py:513: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3609.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# from torchvision.models import swin_t,  SwinTransformer\n",
    "from myswinmodel import SwinTransformer\n",
    "\n",
    "# model = swin_t()\n",
    "# model = SwinTransformer(\n",
    "#     embed_dim = 512,\n",
    "# )\n",
    "model = SwinTransformer(\n",
    "    patch_size=3, \n",
    "    in_chans=128, \n",
    "    num_classes=2, \n",
    "    embed_dim=96, \n",
    "    depths=(2, 2, 6, 2), \n",
    "    num_heads=(3, 6, 12, 24),\n",
    "    window_size=3, \n",
    "    mlp_ratio=4.,\n",
    "    qkv_bias=True, \n",
    "    drop_rate=0.1,\n",
    "    attn_drop_rate=0.1, \n",
    "    drop_path_rate=0.2\n",
    "    # eca_kernel_size=3  # 设置 ECA 的卷积核大小\n",
    ")\n",
    "\n",
    "# 打印模型结构（可选）\n",
    "# print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "empty(): argument 'size' failed to unpack the object at pos 3 with error \"type must be tuple of ints,but got list\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m  \u001b[38;5;66;03m# 分类类别数量\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# 初始化模型\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSwinTransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43membed_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdepths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdepths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwindow_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstochastic_depth_prob\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstochastic_depth_prob\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/autodl-tmp/.autodl/kinlaw/mi_swin/myswinmodel.py:561\u001b[0m, in \u001b[0;36mSwinTransformer.__init__\u001b[0;34m(self, patch_size, in_chans, num_classes, embed_dim, depths, num_heads, window_size, mlp_ratio, qkv_bias, drop_rate, attn_drop_rate, drop_path_rate, norm_layer, patch_norm, use_checkpoint, **kwargs)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meca \u001b[38;5;241m=\u001b[39m ECAModuleWithLinear(channel_nums\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m)\n\u001b[1;32m    560\u001b[0m \u001b[38;5;66;03m# split image into non-overlapping patches\u001b[39;00m\n\u001b[0;32m--> 561\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_embed \u001b[38;5;241m=\u001b[39m \u001b[43mPatchEmbed\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_c\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43min_chans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnorm_layer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm_layer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpatch_norm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_drop \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDropout(p\u001b[38;5;241m=\u001b[39mdrop_rate)\n\u001b[1;32m    566\u001b[0m \u001b[38;5;66;03m# stochastic depth\u001b[39;00m\n",
      "File \u001b[0;32m~/autodl-tmp/.autodl/kinlaw/mi_swin/myswinmodel.py:145\u001b[0m, in \u001b[0;36mPatchEmbed.__init__\u001b[0;34m(self, patch_size, in_c, embed_dim, norm_layer)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_chans \u001b[38;5;241m=\u001b[39m in_c\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim \u001b[38;5;241m=\u001b[39m embed_dim\n\u001b[0;32m--> 145\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproj \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;241m=\u001b[39m norm_layer(embed_dim) \u001b[38;5;28;01mif\u001b[39;00m norm_layer \u001b[38;5;28;01melse\u001b[39;00m nn\u001b[38;5;241m.\u001b[39mIdentity()\n",
      "File \u001b[0;32m~/autodl-tmp/conda/envs/swin_law/lib/python3.8/site-packages/torch/nn/modules/conv.py:445\u001b[0m, in \u001b[0;36mConv2d.__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, padding_mode, device, dtype)\u001b[0m\n\u001b[1;32m    443\u001b[0m padding_ \u001b[38;5;241m=\u001b[39m padding \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(padding, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m _pair(padding)\n\u001b[1;32m    444\u001b[0m dilation_ \u001b[38;5;241m=\u001b[39m _pair(dilation)\n\u001b[0;32m--> 445\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m    \u001b[49m\u001b[43min_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdilation_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pair\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfactory_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/autodl-tmp/conda/envs/swin_law/lib/python3.8/site-packages/torch/nn/modules/conv.py:132\u001b[0m, in \u001b[0;36m_ConvNd.__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, bias, padding_mode, device, dtype)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m Parameter(torch\u001b[38;5;241m.\u001b[39mempty(\n\u001b[1;32m    130\u001b[0m         (in_channels, out_channels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m groups, \u001b[38;5;241m*\u001b[39mkernel_size), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfactory_kwargs))\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m Parameter(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_channels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkernel_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfactory_kwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bias:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;241m=\u001b[39m Parameter(torch\u001b[38;5;241m.\u001b[39mempty(out_channels, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfactory_kwargs))\n",
      "\u001b[0;31mTypeError\u001b[0m: empty(): argument 'size' failed to unpack the object at pos 3 with error \"type must be tuple of ints,but got list\""
     ]
    }
   ],
   "source": [
    "# 配置模型参数\n",
    "patch_size = [4, 4]\n",
    "embed_dim = 96\n",
    "depths = [2, 2, 6, 2]\n",
    "num_heads = [3, 6, 12, 24]\n",
    "window_size = [7, 7]\n",
    "stochastic_depth_prob = 0.1\n",
    "num_classes = 1000  # 分类类别数量\n",
    "\n",
    "# 初始化模型\n",
    "model = SwinTransformer(\n",
    "    patch_size=patch_size,\n",
    "    embed_dim=embed_dim,\n",
    "    depths=depths,\n",
    "    num_heads=num_heads,\n",
    "    window_size=window_size,\n",
    "    stochastic_depth_prob=stochastic_depth_prob,\n",
    "    num_classes=num_classes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.features[0][0] = torch.nn.Conv2d(128, 512, kernel_size=(2, 2), stride=(2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "band_dict = {\n",
    "    # 'theta': [8, 12],\n",
    "    # 'alpha': [8, 20],\n",
    "    # 'beta': [8, 30],\n",
    "    # 'low_beta': [12, 20],\n",
    "    # 'high_beta': [15, 20],\n",
    "    'gamma': [15, 30],\n",
    "    # 'high_gamma': [20, 30],\n",
    "    # 'mu': [8, 15],\n",
    "    # 'range_1': [8, 12],\n",
    "    # 'range_2': [9, 13],\n",
    "    # 'range_3': [10, 14],\n",
    "    # 'range_4': [11, 15],\n",
    "    # 'range_5': [12, 16],\n",
    "    # 'range_6': [13, 17],\n",
    "    # 'range_7': [14, 18],\n",
    "    # 'range_8': [15, 19],\n",
    "    # 'range_9': [16, 20],\n",
    "    # 'range_10': [17, 21],\n",
    "    # 'range_11': [18, 22],\n",
    "    # 'range_12': [19, 23],\n",
    "    # 'range_13': [20, 24],\n",
    "    # 'range_14': [21, 25],\n",
    "    # 'range_15': [22, 26],\n",
    "    # 'range_16': [23, 27],\n",
    "    # 'range_17': [24, 28],\n",
    "    # 'range_18': [25, 29],\n",
    "    # 'range_19': [26, 30]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-11-25 10:36:33] INFO (torcheeg/MainThread) 🔍 | Processing EEG data. Processed EEG data has been cached to \u001b[92m.torcheeg/datasets_1732502193666_03npN\u001b[0m.\n",
      "[2024-11-25 10:36:33] INFO (torcheeg/MainThread) ⏳ | Monitoring the detailed processing of a record for debugging. The processing of other records will only be reported in percentage to keep it clean.\n",
      "[PROCESS]: 100%|██████████| 1/1 [00:00<00:00, 51.45it/s]\n",
      "\n",
      "[RECORD ../kinlaw12/dataset/edffile/sub-30/eeg/sub-30_task-motor-imagery_eeg.edf]: 0it [00:00, ?it/s]\u001b[A\n",
      "[RECORD ../kinlaw12/dataset/edffile/sub-30/eeg/sub-30_task-motor-imagery_eeg.edf]: 1it [00:00,  8.56it/s]\u001b[A\n",
      "[RECORD ../kinlaw12/dataset/edffile/sub-30/eeg/sub-30_task-motor-imagery_eeg.edf]: 2it [00:00,  8.66it/s]\u001b[A\n",
      "[RECORD ../kinlaw12/dataset/edffile/sub-30/eeg/sub-30_task-motor-imagery_eeg.edf]: 23it [00:00, 92.90it/s]\u001b[A\n",
      "[RECORD ../kinlaw12/dataset/edffile/sub-30/eeg/sub-30_task-motor-imagery_eeg.edf]: 45it [00:00, 140.05it/s]\u001b[A\n",
      "[RECORD ../kinlaw12/dataset/edffile/sub-30/eeg/sub-30_task-motor-imagery_eeg.edf]: 68it [00:00, 168.32it/s]\u001b[A\n",
      "[RECORD ../kinlaw12/dataset/edffile/sub-30/eeg/sub-30_task-motor-imagery_eeg.edf]: 90it [00:00, 184.29it/s]\u001b[A\n",
      "[RECORD ../kinlaw12/dataset/edffile/sub-30/eeg/sub-30_task-motor-imagery_eeg.edf]: 112it [00:00, 192.95it/s]\u001b[A\n",
      "[RECORD ../kinlaw12/dataset/edffile/sub-30/eeg/sub-30_task-motor-imagery_eeg.edf]: 134it [00:00, 200.60it/s]\u001b[A\n",
      "[RECORD ../kinlaw12/dataset/edffile/sub-30/eeg/sub-30_task-motor-imagery_eeg.edf]: 156it [00:00, 206.44it/s]\u001b[A\n",
      "[RECORD ../kinlaw12/dataset/edffile/sub-30/eeg/sub-30_task-motor-imagery_eeg.edf]: 178it [00:01, 209.63it/s]\u001b[A\n",
      "[RECORD ../kinlaw12/dataset/edffile/sub-30/eeg/sub-30_task-motor-imagery_eeg.edf]: 200it [00:01, 209.77it/s]\u001b[A\n",
      "[RECORD ../kinlaw12/dataset/edffile/sub-30/eeg/sub-30_task-motor-imagery_eeg.edf]: 222it [00:01, 211.41it/s]\u001b[A\n",
      "[RECORD ../kinlaw12/dataset/edffile/sub-30/eeg/sub-30_task-motor-imagery_eeg.edf]: 245it [00:01, 214.24it/s]\u001b[A\n",
      "[RECORD ../kinlaw12/dataset/edffile/sub-30/eeg/sub-30_task-motor-imagery_eeg.edf]: 268it [00:01, 216.34it/s]\u001b[A\n",
      "[RECORD ../kinlaw12/dataset/edffile/sub-30/eeg/sub-30_task-motor-imagery_eeg.edf]: 291it [00:01, 217.35it/s]\u001b[A\n",
      "[RECORD ../kinlaw12/dataset/edffile/sub-30/eeg/sub-30_task-motor-imagery_eeg.edf]: 314it [00:01, 219.13it/s]\u001b[A\n",
      "                                                                                                            \u001b[A[2024-11-25 10:36:37] INFO (torcheeg/MainThread) ✅ | All processed EEG data has been cached to .torcheeg/datasets_1732502193666_03npN.\n",
      "[2024-11-25 10:36:37] INFO (torcheeg/MainThread) 😊 | Please set \u001b[92mio_path\u001b[0m to \u001b[92m.torcheeg/datasets_1732502193666_03npN\u001b[0m for the next run, to directly read from the cache if you wish to skip the data processing step.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 7, 5])\n",
      "280\n"
     ]
    }
   ],
   "source": [
    "from strokescopy import StrokePatientsMIProcessedDataset\n",
    "import scipy\n",
    "from strokesdict import STROKEPATIENTSMI_LOCATION_DICT\n",
    "from torcheeg.transforms import Select,BandSignal,Compose,Lambda,ToTensor,BandDifferentialEntropy,Resize\n",
    "from to import ToGrid\n",
    "from typing import Callable, Dict, Union, List\n",
    "import numpy as np\n",
    "import soxr\n",
    "from downsample import SetSamplingRate\n",
    "from baseline import BaselineCorrection\n",
    "from base_transform import EEGTransform\n",
    "\n",
    "\n",
    "dataset = StrokePatientsMIProcessedDataset(root_path='../kinlaw12/dataset',\n",
    "                                        #    io_path='.torcheeg/datasets_1732498318348_MCqHM',\n",
    "                        chunk_size=500,  # 1 second\n",
    "                        overlap = 250,\n",
    "                        offline_transform=Compose(\n",
    "                            [\n",
    "                             BaselineCorrection(),SetSamplingRate(origin_sampling_rate=500,target_sampling_rate=128),ToGrid(channel_location_dict=STROKEPATIENTSMI_LOCATION_DICT)]),\n",
    "                        online_transform=Compose([ToTensor()]),\n",
    "                        label_transform=Select('label'),\n",
    "                        num_worker=8\n",
    ")\n",
    "print(dataset[0][0].shape) #EEG shape(1,30,500)\n",
    "# print(dataset[0][1])  # label (int)\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将模型移动到 GPU（如果可用）\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数和优化器\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-11-25 09:47:30] INFO (torcheeg/MainThread) 📊 | Create the split of train and test set.\n",
      "[2024-11-25 09:47:30] INFO (torcheeg/MainThread) 😊 | Please set \u001b[92msplit_path\u001b[0m to \u001b[92m.torcheeg/model_selection_1732499250769_yXBHP\u001b[0m for the next run, if you want to use the same setting for the experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Epoch [1/100], Loss: 1.6577, Accuracy: 52.00%\n",
      "Validation Accuracy: 50.00%\n",
      "Epoch [2/100], Loss: 0.8012, Accuracy: 53.00%\n",
      "Validation Accuracy: 50.00%\n",
      "Epoch [3/100], Loss: 0.7218, Accuracy: 48.00%\n",
      "Validation Accuracy: 50.00%\n",
      "Epoch [4/100], Loss: 0.7605, Accuracy: 50.50%\n",
      "Validation Accuracy: 50.00%\n",
      "Epoch [5/100], Loss: 0.7552, Accuracy: 47.00%\n",
      "Validation Accuracy: 50.00%\n",
      "Epoch [6/100], Loss: 0.7173, Accuracy: 50.50%\n",
      "Validation Accuracy: 50.00%\n",
      "Epoch [7/100], Loss: 0.7253, Accuracy: 47.00%\n",
      "Validation Accuracy: 50.00%\n",
      "Epoch [8/100], Loss: 0.7052, Accuracy: 51.50%\n",
      "Validation Accuracy: 50.00%\n",
      "Epoch [9/100], Loss: 0.7072, Accuracy: 51.50%\n",
      "Validation Accuracy: 50.00%\n",
      "Epoch [10/100], Loss: 0.7257, Accuracy: 47.50%\n",
      "Validation Accuracy: 50.00%\n",
      "Epoch [11/100], Loss: 0.7060, Accuracy: 51.50%\n",
      "Validation Accuracy: 50.00%\n",
      "Epoch [12/100], Loss: 0.7201, Accuracy: 50.50%\n",
      "Validation Accuracy: 50.00%\n",
      "Epoch [13/100], Loss: 0.7298, Accuracy: 50.50%\n",
      "Validation Accuracy: 50.00%\n",
      "Epoch [14/100], Loss: 0.7124, Accuracy: 51.00%\n",
      "Validation Accuracy: 50.00%\n",
      "Epoch [15/100], Loss: 0.7118, Accuracy: 50.50%\n",
      "Validation Accuracy: 50.00%\n",
      "Epoch [16/100], Loss: 0.7494, Accuracy: 50.00%\n",
      "Validation Accuracy: 50.00%\n",
      "Epoch [17/100], Loss: 0.7093, Accuracy: 51.00%\n",
      "Validation Accuracy: 50.00%\n",
      "Epoch [18/100], Loss: 0.7227, Accuracy: 50.00%\n",
      "Validation Accuracy: 50.00%\n",
      "Epoch [19/100], Loss: 0.6986, Accuracy: 51.00%\n",
      "Validation Accuracy: 50.00%\n",
      "Epoch [20/100], Loss: 0.7194, Accuracy: 49.50%\n",
      "Validation Accuracy: 50.00%\n",
      "Epoch [21/100], Loss: 0.7137, Accuracy: 47.00%\n",
      "Validation Accuracy: 50.00%\n",
      "Epoch [22/100], Loss: 0.7236, Accuracy: 48.50%\n",
      "Validation Accuracy: 50.00%\n",
      "Epoch [23/100], Loss: 0.7173, Accuracy: 43.00%\n",
      "Validation Accuracy: 50.00%\n",
      "Epoch [24/100], Loss: 0.7038, Accuracy: 49.50%\n",
      "Validation Accuracy: 50.00%\n",
      "Epoch [25/100], Loss: 0.6949, Accuracy: 51.50%\n",
      "Validation Accuracy: 50.00%\n",
      "Epoch [26/100], Loss: 0.7197, Accuracy: 50.00%\n",
      "Validation Accuracy: 50.00%\n",
      "Epoch [27/100], Loss: 0.6867, Accuracy: 55.00%\n",
      "Validation Accuracy: 50.00%\n",
      "Epoch [28/100], Loss: 0.7404, Accuracy: 41.00%\n",
      "Validation Accuracy: 50.00%\n",
      "Epoch [29/100], Loss: 0.7352, Accuracy: 43.00%\n",
      "Validation Accuracy: 50.00%\n",
      "Epoch [30/100], Loss: 0.7393, Accuracy: 50.00%\n",
      "Validation Accuracy: 50.00%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 42\u001b[0m\n\u001b[1;32m     40\u001b[0m     _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     41\u001b[0m     total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 42\u001b[0m     correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[43mpredicted\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     44\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# 打印每个epoch的训练情况\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torcheeg.model_selection import KFoldGroupbyTrial\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 使用 KFold 划分数据集（这里使用 5-fold 交叉验证）\n",
    "kf = KFoldGroupbyTrial(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "for i, (train_dataset, test_dataset) in enumerate(kf.split(dataset)):\n",
    "    print(f\"Fold {i + 1}\")\n",
    "    \n",
    "    # 创建 DataLoader\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=8)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=8)\n",
    "    num_epochs = 100  # 你可以调整为合适的训练轮数\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # 切换到训练模式\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            # 将数据移动到设备（GPU或CPU）\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # 清空梯度\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 前向传播\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # 计算损失\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # 反向传播\n",
    "            loss.backward()\n",
    "\n",
    "            # 更新参数\n",
    "            optimizer.step()\n",
    "\n",
    "            # 计算准确率\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # 打印每个epoch的训练情况\n",
    "        train_accuracy = 100 * correct / total\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {train_accuracy:.2f}%')\n",
    "\n",
    "        # 评估模型在测试集上的表现\n",
    "        model.eval()  # 切换到评估模式\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():  # 不计算梯度\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        test_accuracy = 100 * correct / total\n",
    "        print(f'Validation Accuracy: {test_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "HYPERPARAMETERS = {\n",
    "    \"seed\": 42,\n",
    "    \"batch_size\": 32,\n",
    "    \"num_windows\": 2,\n",
    "    \"F1\": 16,\n",
    "    \"D\": 4,\n",
    "    \"lr\": 1e-3,\n",
    "    \"weight_decay\": 0,\n",
    "    \"num_epochs\": 50,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-11-25 10:36:58] INFO (torcheeg/MainThread) 📊 | Create the split of train and test set.\n",
      "[2024-11-25 10:36:58] INFO (torcheeg/MainThread) 😊 | Please set \u001b[92msplit_path\u001b[0m to \u001b[92m.torcheeg/model_selection_1732502218257_XuuCS\u001b[0m for the next run, if you want to use the same setting for the experiment.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/root/autodl-tmp/conda/envs/swin_law/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8ae9132e6384f02839947977f6707a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-11-25 10:37:00] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 1.375 train_accuracy: 0.565 \n",
      "\n",
      "[2024-11-25 10:37:03] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.878 train_accuracy: 0.500 \n",
      "\n",
      "[2024-11-25 10:37:05] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.758 train_accuracy: 0.520 \n",
      "\n",
      "[2024-11-25 10:37:08] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.818 train_accuracy: 0.485 \n",
      "\n",
      "[2024-11-25 10:37:11] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.812 train_accuracy: 0.540 \n",
      "\n",
      "[2024-11-25 10:37:14] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.718 train_accuracy: 0.495 \n",
      "\n",
      "[2024-11-25 10:37:16] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.732 train_accuracy: 0.495 \n",
      "\n",
      "[2024-11-25 10:37:19] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.768 train_accuracy: 0.460 \n",
      "\n",
      "[2024-11-25 10:37:22] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.719 train_accuracy: 0.505 \n",
      "\n",
      "[2024-11-25 10:37:24] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.726 train_accuracy: 0.490 \n",
      "\n",
      "[2024-11-25 10:37:27] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.734 train_accuracy: 0.425 \n",
      "\n",
      "[2024-11-25 10:37:30] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.788 train_accuracy: 0.505 \n",
      "\n",
      "[2024-11-25 10:37:33] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.704 train_accuracy: 0.585 \n",
      "\n",
      "[2024-11-25 10:37:35] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.714 train_accuracy: 0.490 \n",
      "\n",
      "[2024-11-25 10:37:38] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.711 train_accuracy: 0.515 \n",
      "\n",
      "[2024-11-25 10:37:41] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.716 train_accuracy: 0.455 \n",
      "\n",
      "[2024-11-25 10:37:43] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.723 train_accuracy: 0.505 \n",
      "\n",
      "[2024-11-25 10:37:46] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.769 train_accuracy: 0.480 \n",
      "\n",
      "[2024-11-25 10:37:49] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.721 train_accuracy: 0.520 \n",
      "\n",
      "[2024-11-25 10:37:51] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.690 train_accuracy: 0.570 \n",
      "\n",
      "[2024-11-25 10:37:54] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.721 train_accuracy: 0.465 \n",
      "\n",
      "[2024-11-25 10:37:57] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.703 train_accuracy: 0.500 \n",
      "\n",
      "[2024-11-25 10:37:59] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.706 train_accuracy: 0.445 \n",
      "\n",
      "[2024-11-25 10:38:02] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.719 train_accuracy: 0.455 \n",
      "\n",
      "[2024-11-25 10:38:05] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.704 train_accuracy: 0.500 \n",
      "\n",
      "[2024-11-25 10:38:07] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.715 train_accuracy: 0.485 \n",
      "\n",
      "[2024-11-25 10:38:10] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.702 train_accuracy: 0.460 \n",
      "\n",
      "[2024-11-25 10:38:13] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.722 train_accuracy: 0.440 \n",
      "\n",
      "[2024-11-25 10:38:15] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.722 train_accuracy: 0.430 \n",
      "\n",
      "[2024-11-25 10:38:18] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.698 train_accuracy: 0.545 \n",
      "\n",
      "[2024-11-25 10:38:21] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.701 train_accuracy: 0.535 \n",
      "\n",
      "[2024-11-25 10:38:23] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.704 train_accuracy: 0.510 \n",
      "\n",
      "[2024-11-25 10:38:26] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.712 train_accuracy: 0.485 \n",
      "\n",
      "[2024-11-25 10:38:29] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.703 train_accuracy: 0.460 \n",
      "\n",
      "[2024-11-25 10:38:31] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.707 train_accuracy: 0.445 \n",
      "\n",
      "[2024-11-25 10:38:34] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.705 train_accuracy: 0.450 \n",
      "\n",
      "[2024-11-25 10:38:37] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.697 train_accuracy: 0.500 \n",
      "\n",
      "[2024-11-25 10:38:39] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.707 train_accuracy: 0.445 \n",
      "\n",
      "[2024-11-25 10:38:42] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.706 train_accuracy: 0.525 \n",
      "\n",
      "[2024-11-25 10:38:45] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.703 train_accuracy: 0.470 \n",
      "\n",
      "[2024-11-25 10:38:47] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.698 train_accuracy: 0.445 \n",
      "\n",
      "[2024-11-25 10:38:50] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.712 train_accuracy: 0.540 \n",
      "\n",
      "[2024-11-25 10:38:53] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.710 train_accuracy: 0.475 \n",
      "\n",
      "[2024-11-25 10:38:55] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.704 train_accuracy: 0.515 \n",
      "\n",
      "[2024-11-25 10:38:58] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.715 train_accuracy: 0.455 \n",
      "\n",
      "[2024-11-25 10:39:01] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.701 train_accuracy: 0.515 \n",
      "\n",
      "[2024-11-25 10:39:03] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.710 train_accuracy: 0.455 \n",
      "\n",
      "[2024-11-25 10:39:06] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.703 train_accuracy: 0.495 \n",
      "\n",
      "[2024-11-25 10:39:09] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.700 train_accuracy: 0.480 \n",
      "\n",
      "[2024-11-25 10:39:11] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.701 train_accuracy: 0.525 \n",
      "\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b96e13877cf4f59ac5b8f06648affc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-11-25 10:39:13] INFO (torcheeg/MainThread) \n",
      "[Test] test_loss: 0.693 test_accuracy: 0.500 \n",
      "\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy                 0.5\n",
      "        test_loss           0.6933653354644775\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Fold 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdc322ea95e64e36b2ecc4188dbb2377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-11-25 10:39:15] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.721 train_accuracy: 0.465 \n",
      "\n",
      "[2024-11-25 10:39:18] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.712 train_accuracy: 0.465 \n",
      "\n",
      "[2024-11-25 10:39:20] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.720 train_accuracy: 0.500 \n",
      "\n",
      "[2024-11-25 10:39:23] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.706 train_accuracy: 0.495 \n",
      "\n",
      "[2024-11-25 10:39:26] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.737 train_accuracy: 0.490 \n",
      "\n",
      "[2024-11-25 10:39:29] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.715 train_accuracy: 0.480 \n",
      "\n",
      "[2024-11-25 10:39:32] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.709 train_accuracy: 0.505 \n",
      "\n",
      "[2024-11-25 10:39:35] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.716 train_accuracy: 0.470 \n",
      "\n",
      "[2024-11-25 10:39:38] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.723 train_accuracy: 0.470 \n",
      "\n",
      "[2024-11-25 10:39:41] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.709 train_accuracy: 0.550 \n",
      "\n",
      "[2024-11-25 10:39:44] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.712 train_accuracy: 0.485 \n",
      "\n",
      "[2024-11-25 10:39:47] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.702 train_accuracy: 0.490 \n",
      "\n",
      "[2024-11-25 10:39:49] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.697 train_accuracy: 0.495 \n",
      "\n",
      "[2024-11-25 10:39:52] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.715 train_accuracy: 0.490 \n",
      "\n",
      "[2024-11-25 10:39:55] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.702 train_accuracy: 0.450 \n",
      "\n",
      "[2024-11-25 10:39:58] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.702 train_accuracy: 0.500 \n",
      "\n",
      "[2024-11-25 10:40:01] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.704 train_accuracy: 0.510 \n",
      "\n",
      "[2024-11-25 10:40:04] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.723 train_accuracy: 0.445 \n",
      "\n",
      "[2024-11-25 10:40:07] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.694 train_accuracy: 0.500 \n",
      "\n",
      "[2024-11-25 10:40:10] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.710 train_accuracy: 0.425 \n",
      "\n",
      "[2024-11-25 10:40:13] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.704 train_accuracy: 0.410 \n",
      "\n",
      "[2024-11-25 10:40:16] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.701 train_accuracy: 0.515 \n",
      "\n",
      "[2024-11-25 10:40:19] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.703 train_accuracy: 0.475 \n",
      "\n",
      "[2024-11-25 10:40:22] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.703 train_accuracy: 0.450 \n",
      "\n",
      "[2024-11-25 10:40:24] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.710 train_accuracy: 0.450 \n",
      "\n",
      "[2024-11-25 10:40:27] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.688 train_accuracy: 0.545 \n",
      "\n",
      "[2024-11-25 10:40:30] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.701 train_accuracy: 0.485 \n",
      "\n",
      "[2024-11-25 10:40:33] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.707 train_accuracy: 0.475 \n",
      "\n",
      "[2024-11-25 10:40:36] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.707 train_accuracy: 0.435 \n",
      "\n",
      "[2024-11-25 10:40:39] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.695 train_accuracy: 0.520 \n",
      "\n",
      "[2024-11-25 10:40:42] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.705 train_accuracy: 0.500 \n",
      "\n",
      "[2024-11-25 10:40:45] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.703 train_accuracy: 0.505 \n",
      "\n",
      "[2024-11-25 10:40:47] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.704 train_accuracy: 0.500 \n",
      "\n",
      "[2024-11-25 10:40:50] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.717 train_accuracy: 0.430 \n",
      "\n",
      "[2024-11-25 10:40:53] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.720 train_accuracy: 0.460 \n",
      "\n",
      "[2024-11-25 10:40:56] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.708 train_accuracy: 0.455 \n",
      "\n",
      "[2024-11-25 10:40:59] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.704 train_accuracy: 0.485 \n",
      "\n",
      "[2024-11-25 10:41:02] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.700 train_accuracy: 0.485 \n",
      "\n",
      "[2024-11-25 10:41:05] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.703 train_accuracy: 0.500 \n",
      "\n",
      "[2024-11-25 10:41:08] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.697 train_accuracy: 0.495 \n",
      "\n",
      "[2024-11-25 10:41:10] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.710 train_accuracy: 0.465 \n",
      "\n",
      "[2024-11-25 10:41:13] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.693 train_accuracy: 0.520 \n",
      "\n",
      "[2024-11-25 10:41:16] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.696 train_accuracy: 0.555 \n",
      "\n",
      "[2024-11-25 10:41:19] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.701 train_accuracy: 0.475 \n",
      "\n",
      "[2024-11-25 10:41:22] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.710 train_accuracy: 0.460 \n",
      "\n",
      "[2024-11-25 10:41:25] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.704 train_accuracy: 0.475 \n",
      "\n",
      "[2024-11-25 10:41:28] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.698 train_accuracy: 0.500 \n",
      "\n",
      "[2024-11-25 10:41:31] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.697 train_accuracy: 0.520 \n",
      "\n",
      "[2024-11-25 10:41:34] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.700 train_accuracy: 0.470 \n",
      "\n",
      "[2024-11-25 10:41:37] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.703 train_accuracy: 0.575 \n",
      "\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75737f08f5c94907a19dc6f591d7bbb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-11-25 10:41:39] INFO (torcheeg/MainThread) \n",
      "[Test] test_loss: 0.699 test_accuracy: 0.500 \n",
      "\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy                 0.5\n",
      "        test_loss           0.6991736888885498\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Fold 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fed029e1b254b1d98550c15dd7b84ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-11-25 10:41:41] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.709 train_accuracy: 0.525 \n",
      "\n",
      "[2024-11-25 10:41:44] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.704 train_accuracy: 0.480 \n",
      "\n",
      "[2024-11-25 10:41:46] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.699 train_accuracy: 0.460 \n",
      "\n",
      "[2024-11-25 10:41:49] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.705 train_accuracy: 0.450 \n",
      "\n",
      "[2024-11-25 10:41:52] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.690 train_accuracy: 0.540 \n",
      "\n",
      "[2024-11-25 10:41:55] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.720 train_accuracy: 0.465 \n",
      "\n",
      "[2024-11-25 10:41:58] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.730 train_accuracy: 0.415 \n",
      "\n",
      "[2024-11-25 10:42:01] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.706 train_accuracy: 0.505 \n",
      "\n",
      "[2024-11-25 10:42:03] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.705 train_accuracy: 0.480 \n",
      "\n",
      "[2024-11-25 10:42:06] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.707 train_accuracy: 0.505 \n",
      "\n",
      "[2024-11-25 10:42:09] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.703 train_accuracy: 0.490 \n",
      "\n",
      "[2024-11-25 10:42:12] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.701 train_accuracy: 0.425 \n",
      "\n",
      "[2024-11-25 10:42:15] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.699 train_accuracy: 0.440 \n",
      "\n",
      "[2024-11-25 10:42:18] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.704 train_accuracy: 0.505 \n",
      "\n",
      "[2024-11-25 10:42:21] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.698 train_accuracy: 0.460 \n",
      "\n",
      "[2024-11-25 10:42:23] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.706 train_accuracy: 0.485 \n",
      "\n",
      "[2024-11-25 10:42:26] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.701 train_accuracy: 0.465 \n",
      "\n",
      "[2024-11-25 10:42:29] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.698 train_accuracy: 0.515 \n",
      "\n",
      "[2024-11-25 10:42:32] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.703 train_accuracy: 0.475 \n",
      "\n",
      "[2024-11-25 10:42:34] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.700 train_accuracy: 0.450 \n",
      "\n",
      "[2024-11-25 10:42:37] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.695 train_accuracy: 0.480 \n",
      "\n",
      "[2024-11-25 10:42:40] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.701 train_accuracy: 0.455 \n",
      "\n",
      "[2024-11-25 10:42:43] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.697 train_accuracy: 0.430 \n",
      "\n",
      "[2024-11-25 10:42:46] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.698 train_accuracy: 0.520 \n",
      "\n",
      "[2024-11-25 10:42:49] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.695 train_accuracy: 0.535 \n",
      "\n",
      "[2024-11-25 10:42:51] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.701 train_accuracy: 0.485 \n",
      "\n",
      "[2024-11-25 10:42:54] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.701 train_accuracy: 0.470 \n",
      "\n",
      "[2024-11-25 10:42:57] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.701 train_accuracy: 0.475 \n",
      "\n",
      "[2024-11-25 10:43:00] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.695 train_accuracy: 0.530 \n",
      "\n",
      "[2024-11-25 10:43:03] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.703 train_accuracy: 0.475 \n",
      "\n",
      "[2024-11-25 10:43:05] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.697 train_accuracy: 0.505 \n",
      "\n",
      "[2024-11-25 10:43:08] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.699 train_accuracy: 0.500 \n",
      "\n",
      "[2024-11-25 10:43:11] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.694 train_accuracy: 0.450 \n",
      "\n",
      "[2024-11-25 10:43:14] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.703 train_accuracy: 0.460 \n",
      "\n",
      "[2024-11-25 10:43:17] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.700 train_accuracy: 0.440 \n",
      "\n",
      "[2024-11-25 10:43:19] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.700 train_accuracy: 0.480 \n",
      "\n",
      "[2024-11-25 10:43:22] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.693 train_accuracy: 0.535 \n",
      "\n",
      "[2024-11-25 10:43:25] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.700 train_accuracy: 0.515 \n",
      "\n",
      "[2024-11-25 10:43:28] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.706 train_accuracy: 0.510 \n",
      "\n",
      "[2024-11-25 10:43:31] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.694 train_accuracy: 0.550 \n",
      "\n",
      "[2024-11-25 10:43:34] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.701 train_accuracy: 0.525 \n",
      "\n",
      "[2024-11-25 10:43:37] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.698 train_accuracy: 0.450 \n",
      "\n",
      "[2024-11-25 10:43:40] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.698 train_accuracy: 0.495 \n",
      "\n",
      "[2024-11-25 10:43:43] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.699 train_accuracy: 0.495 \n",
      "\n",
      "[2024-11-25 10:43:46] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.699 train_accuracy: 0.470 \n",
      "\n",
      "[2024-11-25 10:43:48] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.701 train_accuracy: 0.520 \n",
      "\n",
      "[2024-11-25 10:43:51] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.711 train_accuracy: 0.445 \n",
      "\n",
      "[2024-11-25 10:43:54] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.692 train_accuracy: 0.530 \n",
      "\n",
      "[2024-11-25 10:43:57] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.696 train_accuracy: 0.545 \n",
      "\n",
      "[2024-11-25 10:44:00] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.699 train_accuracy: 0.420 \n",
      "\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9e599c553054becbaf8c856aee4e352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-11-25 10:44:02] INFO (torcheeg/MainThread) \n",
      "[Test] test_loss: 0.693 test_accuracy: 0.500 \n",
      "\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy                 0.5\n",
      "        test_loss           0.6932192444801331\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Fold 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85063920844a40df8b283cd217db95fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-11-25 10:44:04] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.699 train_accuracy: 0.454 \n",
      "\n",
      "[2024-11-25 10:44:07] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.696 train_accuracy: 0.496 \n",
      "\n",
      "[2024-11-25 10:44:10] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.706 train_accuracy: 0.483 \n",
      "\n",
      "[2024-11-25 10:44:13] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.698 train_accuracy: 0.438 \n",
      "\n",
      "[2024-11-25 10:44:16] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.703 train_accuracy: 0.525 \n",
      "\n",
      "[2024-11-25 10:44:20] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.695 train_accuracy: 0.508 \n",
      "\n",
      "[2024-11-25 10:44:23] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.704 train_accuracy: 0.458 \n",
      "\n",
      "[2024-11-25 10:44:26] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.697 train_accuracy: 0.442 \n",
      "\n",
      "[2024-11-25 10:44:29] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.700 train_accuracy: 0.521 \n",
      "\n",
      "[2024-11-25 10:44:32] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.699 train_accuracy: 0.483 \n",
      "\n",
      "[2024-11-25 10:44:35] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.703 train_accuracy: 0.479 \n",
      "\n",
      "[2024-11-25 10:44:38] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.702 train_accuracy: 0.529 \n",
      "\n",
      "[2024-11-25 10:44:41] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.695 train_accuracy: 0.483 \n",
      "\n",
      "[2024-11-25 10:44:44] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.701 train_accuracy: 0.463 \n",
      "\n",
      "[2024-11-25 10:44:47] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.697 train_accuracy: 0.492 \n",
      "\n",
      "[2024-11-25 10:44:50] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.699 train_accuracy: 0.496 \n",
      "\n",
      "[2024-11-25 10:44:53] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.697 train_accuracy: 0.525 \n",
      "\n",
      "[2024-11-25 10:44:57] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.701 train_accuracy: 0.479 \n",
      "\n",
      "[2024-11-25 10:45:00] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.704 train_accuracy: 0.475 \n",
      "\n",
      "[2024-11-25 10:45:03] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.702 train_accuracy: 0.454 \n",
      "\n",
      "[2024-11-25 10:45:06] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.695 train_accuracy: 0.496 \n",
      "\n",
      "[2024-11-25 10:45:09] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.699 train_accuracy: 0.496 \n",
      "\n",
      "[2024-11-25 10:45:13] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.696 train_accuracy: 0.496 \n",
      "\n",
      "[2024-11-25 10:45:16] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.698 train_accuracy: 0.450 \n",
      "\n",
      "[2024-11-25 10:45:19] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.699 train_accuracy: 0.458 \n",
      "\n",
      "[2024-11-25 10:45:22] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.697 train_accuracy: 0.450 \n",
      "\n",
      "[2024-11-25 10:45:25] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.699 train_accuracy: 0.454 \n",
      "\n",
      "[2024-11-25 10:45:28] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.696 train_accuracy: 0.492 \n",
      "\n",
      "[2024-11-25 10:45:31] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.700 train_accuracy: 0.438 \n",
      "\n",
      "[2024-11-25 10:45:34] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.694 train_accuracy: 0.483 \n",
      "\n",
      "[2024-11-25 10:45:38] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.697 train_accuracy: 0.475 \n",
      "\n",
      "[2024-11-25 10:45:41] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.696 train_accuracy: 0.463 \n",
      "\n",
      "[2024-11-25 10:45:44] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.697 train_accuracy: 0.458 \n",
      "\n",
      "[2024-11-25 10:45:47] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.698 train_accuracy: 0.471 \n",
      "\n",
      "[2024-11-25 10:45:50] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.694 train_accuracy: 0.504 \n",
      "\n",
      "[2024-11-25 10:45:53] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.696 train_accuracy: 0.496 \n",
      "\n",
      "[2024-11-25 10:45:56] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.695 train_accuracy: 0.488 \n",
      "\n",
      "[2024-11-25 10:46:00] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.701 train_accuracy: 0.475 \n",
      "\n",
      "[2024-11-25 10:46:03] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.695 train_accuracy: 0.529 \n",
      "\n",
      "[2024-11-25 10:46:06] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.692 train_accuracy: 0.512 \n",
      "\n",
      "[2024-11-25 10:46:09] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.708 train_accuracy: 0.467 \n",
      "\n",
      "[2024-11-25 10:46:12] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.697 train_accuracy: 0.479 \n",
      "\n",
      "[2024-11-25 10:46:15] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.697 train_accuracy: 0.475 \n",
      "\n",
      "[2024-11-25 10:46:18] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.697 train_accuracy: 0.442 \n",
      "\n",
      "[2024-11-25 10:46:22] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.696 train_accuracy: 0.483 \n",
      "\n",
      "[2024-11-25 10:46:25] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.693 train_accuracy: 0.512 \n",
      "\n",
      "[2024-11-25 10:46:28] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.699 train_accuracy: 0.479 \n",
      "\n",
      "[2024-11-25 10:46:31] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.697 train_accuracy: 0.492 \n",
      "\n",
      "[2024-11-25 10:46:34] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.696 train_accuracy: 0.496 \n",
      "\n",
      "[2024-11-25 10:46:37] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.697 train_accuracy: 0.500 \n",
      "\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61a530c460c4406a9508a24cb419dd79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-11-25 10:46:39] INFO (torcheeg/MainThread) \n",
      "[Test] test_loss: 0.693 test_accuracy: 0.500 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy                 0.5\n",
      "        test_loss           0.6933857202529907\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "from torcheeg.trainers import ClassifierTrainer\n",
    "import pytorch_lightning as pl\n",
    "from torcheeg.model_selection import KFoldGroupbyTrial\n",
    "from torch.utils.data import DataLoader\n",
    "# 使用 KFold 划分数据集（这里使用 5-fold 交叉验证）\n",
    "kf = KFoldGroupbyTrial(n_splits=4, shuffle=True, random_state=42)\n",
    "for i, (train_dataset, test_dataset) in enumerate(kf.split(dataset)):\n",
    "    print(f\"Fold {i + 1}\")\n",
    "    \n",
    "    # 创建 DataLoader\n",
    "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=8)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=8)\n",
    "    trainer = ClassifierTrainer(model=model,\n",
    "                                num_classes=2,\n",
    "                                lr=HYPERPARAMETERS['lr'],\n",
    "                                weight_decay=HYPERPARAMETERS['weight_decay'],\n",
    "                                accelerator=\"gpu\")\n",
    "    trainer.fit(train_loader,\n",
    "                test_loader,\n",
    "                max_epochs=HYPERPARAMETERS['num_epochs'],\n",
    "                callbacks=[pl.callbacks.ModelCheckpoint(save_last=False)],\n",
    "                enable_progress_bar=True,\n",
    "                enable_model_summary=False,\n",
    "                limit_val_batches=0.0)\n",
    "\n",
    "    trainer.test(test_loader,\n",
    "                enable_progress_bar=True,\n",
    "                enable_model_summary=False)[0]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swin_law",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
