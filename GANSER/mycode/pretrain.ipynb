{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/autodl-tmp/conda/envs/law/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[2025-02-11 15:26:28] INFO (torcheeg/MainThread) ğŸ” | Processing EEG data. Processed EEG data has been cached to \u001b[92m.torcheeg/datasets_1739258788329_UGp5r\u001b[0m.\n",
      "[2025-02-11 15:26:28] INFO (torcheeg/MainThread) â³ | Monitoring the detailed processing of a record for debugging. The processing of other records will only be reported in percentage to keep it clean.\n",
      "[PROCESS]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 89.59it/s]\n",
      "\n",
      "[RECORD ../../mi_swin/subdataset/sourcedata/sub-45/sub-45_task-motor-imagery_eeg.mat]: 0it [00:00, ?it/s]\u001b[A\n",
      "[RECORD ../../mi_swin/subdataset/sourcedata/sub-45/sub-45_task-motor-imagery_eeg.mat]: 1it [00:00,  4.48it/s]\u001b[A\n",
      "[RECORD ../../mi_swin/subdataset/sourcedata/sub-45/sub-45_task-motor-imagery_eeg.mat]: 2it [00:00,  5.89it/s]\u001b[A\n",
      "[RECORD ../../mi_swin/subdataset/sourcedata/sub-45/sub-45_task-motor-imagery_eeg.mat]: 12it [00:00, 36.75it/s]\u001b[A\n",
      "[RECORD ../../mi_swin/subdataset/sourcedata/sub-45/sub-45_task-motor-imagery_eeg.mat]: 23it [00:00, 57.93it/s]\u001b[A\n",
      "[RECORD ../../mi_swin/subdataset/sourcedata/sub-45/sub-45_task-motor-imagery_eeg.mat]: 33it [00:00, 70.47it/s]\u001b[A\n",
      "[RECORD ../../mi_swin/subdataset/sourcedata/sub-45/sub-45_task-motor-imagery_eeg.mat]: 44it [00:00, 79.63it/s]\u001b[A\n",
      "[RECORD ../../mi_swin/subdataset/sourcedata/sub-45/sub-45_task-motor-imagery_eeg.mat]: 55it [00:00, 85.96it/s]\u001b[A\n",
      "[RECORD ../../mi_swin/subdataset/sourcedata/sub-45/sub-45_task-motor-imagery_eeg.mat]: 67it [00:01, 92.91it/s]\u001b[A\n",
      "[RECORD ../../mi_swin/subdataset/sourcedata/sub-45/sub-45_task-motor-imagery_eeg.mat]: 78it [00:01, 94.60it/s]\u001b[A\n",
      "[RECORD ../../mi_swin/subdataset/sourcedata/sub-45/sub-45_task-motor-imagery_eeg.mat]: 89it [00:01, 96.02it/s]\u001b[A\n",
      "[RECORD ../../mi_swin/subdataset/sourcedata/sub-45/sub-45_task-motor-imagery_eeg.mat]: 100it [00:01, 96.82it/s]\u001b[A\n",
      "[RECORD ../../mi_swin/subdataset/sourcedata/sub-45/sub-45_task-motor-imagery_eeg.mat]: 110it [00:01, 96.11it/s]\u001b[A\n",
      "[RECORD ../../mi_swin/subdataset/sourcedata/sub-45/sub-45_task-motor-imagery_eeg.mat]: 120it [00:01, 96.79it/s]\u001b[A\n",
      "[RECORD ../../mi_swin/subdataset/sourcedata/sub-45/sub-45_task-motor-imagery_eeg.mat]: 132it [00:01, 100.12it/s]\u001b[A\n",
      "[RECORD ../../mi_swin/subdataset/sourcedata/sub-45/sub-45_task-motor-imagery_eeg.mat]: 143it [00:01, 99.82it/s] \u001b[A\n",
      "[RECORD ../../mi_swin/subdataset/sourcedata/sub-45/sub-45_task-motor-imagery_eeg.mat]: 154it [00:01, 99.55it/s]\u001b[A\n",
      "[RECORD ../../mi_swin/subdataset/sourcedata/sub-45/sub-45_task-motor-imagery_eeg.mat]: 165it [00:01, 99.46it/s]\u001b[A\n",
      "[RECORD ../../mi_swin/subdataset/sourcedata/sub-45/sub-45_task-motor-imagery_eeg.mat]: 175it [00:02, 99.34it/s]\u001b[A\n",
      "[RECORD ../../mi_swin/subdataset/sourcedata/sub-45/sub-45_task-motor-imagery_eeg.mat]: 185it [00:02, 98.00it/s]\u001b[A\n",
      "[RECORD ../../mi_swin/subdataset/sourcedata/sub-45/sub-45_task-motor-imagery_eeg.mat]: 197it [00:02, 100.81it/s]\u001b[A\n",
      "                                                                                                                \u001b[A[2025-02-11 15:26:32] INFO (torcheeg/MainThread) âœ… | All processed EEG data has been cached to .torcheeg/datasets_1739258788329_UGp5r.\n",
      "[2025-02-11 15:26:32] INFO (torcheeg/MainThread) ğŸ˜Š | Please set \u001b[92mio_path\u001b[0m to \u001b[92m.torcheeg/datasets_1739258788329_UGp5r\u001b[0m for the next run, to directly read from the cache if you wish to skip the data processing step.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 9, 9])\n",
      "0\n",
      "160\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import logging\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from torch import autograd\n",
    "from sklearn import model_selection\n",
    "from torch.utils.data import Dataset, Subset, DataLoader\n",
    "\n",
    "from strokes import StrokePatientsMIDataset\n",
    "from strokesdict import STROKEPATIENTSMI_LOCATION_DICT\n",
    "import scipy\n",
    "from torcheeg.transforms import Select,BandSignal,Compose,ToTensor\n",
    "from to import ToGrid\n",
    "from typing import Callable, Dict, Union, List\n",
    "import numpy as np\n",
    "import soxr\n",
    "from downsample import SetSamplingRate\n",
    "from baseline import BaselineCorrection\n",
    "from torcheeg.transforms import EEGTransform, Select,BandSignal,Compose,ToTensor\n",
    "\n",
    "dataset = StrokePatientsMIDataset(root_path='../../mi_swin/subdataset',\n",
    "                                #   io_path='.torcheeg/datasets_1739252099423_RDowH',\n",
    "                        chunk_size=500,  # 1 second\n",
    "                        overlap = 0,\n",
    "                        offline_transform=Compose(\n",
    "                                [BaselineCorrection(),\n",
    "                                SetSamplingRate(origin_sampling_rate=500,target_sampling_rate=128),\n",
    "                                BandSignal(sampling_rate=128,band_dict={'frequency_range':[8,40]})\n",
    "                                ]),\n",
    "                        online_transform=Compose(\n",
    "                                # [ToTensor()]),\n",
    "                                [ToGrid(STROKEPATIENTSMI_LOCATION_DICT),ToTensor()]),\n",
    "                \n",
    "                        label_transform=Select('label'),\n",
    "                        num_worker=8\n",
    ")\n",
    "print(dataset[0][0].shape) #EEG shape(1,30,128)\n",
    "print(dataset[0][1])  # label (int)\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def delete_folder_if_exists(target_folder_name):\n",
    "    # è·å–çˆ¶æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰å†…å®¹\n",
    "    parent_folder = os.getcwd()\n",
    "    for folder_name in os.listdir(parent_folder):\n",
    "        folder_path = os.path.join(parent_folder, folder_name)\n",
    "\n",
    "        # æ£€æŸ¥æ˜¯å¦æ˜¯æ–‡ä»¶å¤¹å¹¶ä¸”åç§°æ˜¯å¦åŒ¹é…\n",
    "        if os.path.isdir(folder_path) and folder_name == target_folder_name:\n",
    "            try:\n",
    "                # åˆ é™¤ç›®æ ‡æ–‡ä»¶å¤¹\n",
    "                shutil.rmtree(folder_path)\n",
    "                print(f\"å·²åˆ é™¤æ–‡ä»¶å¤¹: {folder_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"åˆ é™¤æ–‡ä»¶å¤¹ {folder_path} æ—¶å‡ºé”™: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(dataset, test_size=0.2, random_state=520, shuffle=True):\n",
    "    n_samples = len(dataset)\n",
    "    indices = np.arange(n_samples)\n",
    "    train_index, test_index = model_selection.train_test_split(\n",
    "        indices,\n",
    "        test_size=test_size,\n",
    "        random_state=random_state,\n",
    "        shuffle=shuffle)\n",
    "\n",
    "    trian_dataset = Subset(dataset, train_index)\n",
    "    test_dataset = Subset(dataset, test_index)\n",
    "\n",
    "    return trian_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256 64\n"
     ]
    }
   ],
   "source": [
    "sub_dataset, test_dataset = train_test_split(dataset=dataset)\n",
    "print(len(sub_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RECEIVED_PARAMS = {\n",
    "    \"c_lr\": 0.00001,\n",
    "    \"g_lr\": 0.00001,\n",
    "    \"d_lr\": 0.00001,\n",
    "    \"weight_gp\": 1.0,\n",
    "    \"weight_decay\": 0.0005,\n",
    "    \"weight_ssl\": 0.5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, in_channels=4, out_channels=128):\n",
    "        super(Generator, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels,\n",
    "                      128,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1,\n",
    "                      bias=True), nn.LeakyReLU())\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(128, 64, kernel_size=5, stride=1, padding=2, bias=True),\n",
    "            nn.LeakyReLU())\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 32, kernel_size=5, stride=1, padding=2, bias=True),\n",
    "            nn.LeakyReLU())\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(32, 16, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.LeakyReLU())\n",
    "        self.delayer1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(16 + 32,\n",
    "                               32,\n",
    "                               kernel_size=3,\n",
    "                               stride=1,\n",
    "                               padding=1,\n",
    "                               bias=True), nn.LeakyReLU())\n",
    "        self.delayer2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32 + 64,\n",
    "                               64,\n",
    "                               kernel_size=3,\n",
    "                               stride=1,\n",
    "                               padding=1,\n",
    "                               bias=True), nn.LeakyReLU())\n",
    "        self.delayer3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64 + 128,\n",
    "                               128,\n",
    "                               kernel_size=3,\n",
    "                               stride=1,\n",
    "                               padding=1,\n",
    "                               bias=True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        #         x = channel_to_location(x)\n",
    "        mask = (x.abs().sum(dim=1, keepdim=True) > 0).float()\n",
    "        out1 = self.layer1(x)\n",
    "        out2 = self.layer2(out1)\n",
    "        out3 = self.layer3(out2)\n",
    "        out = self.layer4(out3)\n",
    "        out = self.delayer1(torch.cat([out, out3], dim=1))\n",
    "        out = self.delayer2(torch.cat([out, out2], dim=1))\n",
    "        out = self.delayer3(torch.cat([out, out1], dim=1))\n",
    "\n",
    "        return out * mask\n",
    "\n",
    "\n",
    "class ResidualConv2d(nn.Module):  # è²Œä¼¼å¹¶æœªä½¿ç”¨è¯¥å‡½æ•°\n",
    "    def __init__(self, in_channels, out_channels, bias=True):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels,\n",
    "                      out_channels,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1,\n",
    "                      bias=bias), nn.SELU(),\n",
    "            nn.Conv2d(out_channels,\n",
    "                      out_channels,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1,\n",
    "                      bias=bias))\n",
    "        self.res = nn.Conv2d(in_channels,\n",
    "                             out_channels,\n",
    "                             kernel_size=1,\n",
    "                             stride=1,\n",
    "                             padding=0,\n",
    "                             bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x) + self.res(x)\n",
    "\n",
    "# è¯†åˆ«æƒ…æ„Ÿéœ€è¦åˆ†æä¸åŒç©ºé—´å°ºåº¦ä¸‹çš„EEGä¿¡å·ï¼Œæ•…å¼•å…¥äº†åŒ…å«ä¸‰ç§ä¸åŒå°ºå¯¸æ»¤æ³¢å™¨çš„InceptionConv2dæ¥æå–å¤šå°ºåº¦ç‰¹å¾å›¾\n",
    "class InceptionConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, bias=True):\n",
    "        super().__init__()\n",
    "        self.conv5x5 = nn.Conv2d(in_channels,\n",
    "                                 out_channels,\n",
    "                                 kernel_size=5,\n",
    "                                 stride=1,\n",
    "                                 padding=2,\n",
    "                                 bias=bias)\n",
    "        self.conv3x3 = nn.Conv2d(in_channels,\n",
    "                                 out_channels,\n",
    "                                 kernel_size=3,\n",
    "                                 stride=1,\n",
    "                                 padding=1,\n",
    "                                 bias=bias)\n",
    "        self.conv1x1 = nn.Conv2d(in_channels,\n",
    "                                 out_channels,\n",
    "                                 kernel_size=1,\n",
    "                                 stride=1,\n",
    "                                 padding=0,\n",
    "                                 bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv5x5(x) + self.conv3x3(x) + self.conv1x1(x)\n",
    "\n",
    "\n",
    "class SeparableConv2d(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 kernel_size=3,\n",
    "                 stride=1,\n",
    "                 padding=1,\n",
    "                 bias=True):\n",
    "        super().__init__()\n",
    "        # ä¸åŒæ—¶é—´ç‚¹çš„äºŒç»´æ•°æ®åˆ†åˆ«è¿›è¡Œå·ç§¯\n",
    "        self.depth = nn.Conv2d(in_channels,\n",
    "                               in_channels,\n",
    "                               kernel_size=kernel_size,\n",
    "                               stride=stride,\n",
    "                               padding=padding,\n",
    "                               groups=in_channels,\n",
    "                               bias=bias)\n",
    "        # å•ä¸ªeegé€šé“è·¨æ—¶é—´ç‚¹è¿›è¡Œå·ç§¯\n",
    "        self.point = nn.Conv2d(in_channels,\n",
    "                               out_channels,\n",
    "                               kernel_size=1,\n",
    "                               stride=stride,\n",
    "                               padding=0,\n",
    "                               bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.depth(x)\n",
    "        x = self.point(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, num_classes, in_channels=4):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.layer1 = nn.Conv2d(in_channels,\n",
    "                                256,\n",
    "                                kernel_size=3,\n",
    "                                stride=1,\n",
    "                                padding=1,\n",
    "                                bias=True)\n",
    "        self.layer2 = nn.Conv2d(256,\n",
    "                                128,\n",
    "                                kernel_size=5,\n",
    "                                stride=1,\n",
    "                                padding=2,\n",
    "                                bias=True)\n",
    "        self.layer3 = nn.Conv2d(128,\n",
    "                                64,\n",
    "                                kernel_size=5,\n",
    "                                stride=1,\n",
    "                                padding=2,\n",
    "                                bias=True)\n",
    "        self.layer4 = SeparableConv2d(64,\n",
    "                                      32,\n",
    "                                      kernel_size=5,\n",
    "                                      stride=1,\n",
    "                                      padding=2,\n",
    "                                      bias=True)\n",
    "        self.layer5 = InceptionConv2d(32, 16)\n",
    "\n",
    "        self.drop = nn.Sequential(nn.SELU())\n",
    "        self.fc1 = nn.Sequential(nn.Linear(9 * 9 * 16, 1024, bias=True),\n",
    "                                 nn.SELU()) # stroke MI dataset çš„ç½‘æ ¼ä¸º 7*5\n",
    "        self.fc2 = nn.Linear(1024, num_classes, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.drop(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.layer5(out)\n",
    "        out = self.drop(out)\n",
    "        out = out.view(out.size(0), -1) # (batch_size, num_features)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/autodl-tmp/conda/envs/law/lib/python3.8/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/native/TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "from model import SwinTransformerGenerator\n",
    "import torch\n",
    "# Instantiate the generator model\n",
    "g_model = SwinTransformerGenerator(in_chans=128,\n",
    "                                     patch_size=2,\n",
    "                                     window_size=3,\n",
    "                                     embed_dim=96,\n",
    "                                     depths=(2, 2, 4, 2),\n",
    "                                     num_heads=(2, 2, 4, 6)\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 128, 9, 9])\n",
      "ans shape: torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "g_model = Generator(in_channels=128, out_channels=128)\n",
    "d_model = Discriminator(in_channels=128, num_classes=2)\n",
    "# æ¨¡æ‹Ÿè¾“å…¥\n",
    "input_tensor = torch.randn(2, 128, 9, 9)  # [batch, 1, 128, 7, 5]\n",
    "output = g_model(input_tensor)\n",
    "ans = d_model(output)\n",
    "print(\"Output shape:\", input_tensor.shape)\n",
    "print(\"ans shape:\", ans.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mask(data, min_r=0.0, max_r=0.5):\n",
    "    # batch_size*channel_num*time_step\n",
    "    data = data.clone()\n",
    "    mask = torch.rand(*data.shape[:2], # éšæœºç”Ÿæˆmaskå€¼ï¼Œ(batch_size, 128, 1, 1)\n",
    "                      *([1] * (len(data.shape) - 2)),\n",
    "                      device=data.device)\n",
    "    # ratio = np.random.beta(1.0, 1.0, size=(data.shape[0], 1, 1, 1))\n",
    "    # ratio = torch.tensor(ratio, device=mask.device).clamp(max=0.5)\n",
    "    ratio = torch.rand(size=(data.shape[0], 1, 1, 1),\n",
    "                       device=mask.device) * (max_r - min_r) + min_r # éšæœºç”Ÿæˆ1ä¸ªé˜ˆå€¼ (batch_size, 1, 1, 1)\n",
    "    mask = mask < ratio # maskå€¼ä½äºé˜ˆå€¼çš„ï¼Œè¢«ç½®é›¶\n",
    "    mask = mask.expand_as(data) # (batch_size, 128, 1, 1) -> (batch_size, 128, 7, 5)\n",
    "    data[mask] = 0.0\n",
    "    return data, ratio\n",
    "\n",
    "\n",
    "def gradient_penalty(model, real, fake):\n",
    "    device = real.device\n",
    "    real = real.data\n",
    "    fake = fake.data\n",
    "    alpha = torch.rand(real.size(0), *([1] * (len(real.shape) - 1))).to(device)\n",
    "    inputs = alpha * real + ((1 - alpha) * fake)\n",
    "    inputs.requires_grad_()\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    gradient = autograd.grad(outputs=outputs,\n",
    "                             inputs=inputs,\n",
    "                             grad_outputs=torch.ones_like(outputs).to(device),\n",
    "                             create_graph=True,\n",
    "                             retain_graph=True,\n",
    "                             only_inputs=True)[0]\n",
    "\n",
    "    gradient = gradient.flatten(1)\n",
    "    return ((gradient.norm(2, dim=1) - 1)**2).mean()\n",
    "\n",
    "\n",
    "class Trainer():\n",
    "    def __init__(self, g_model, d_model, trainer_kwargs={'max_epochs': 10}):\n",
    "        super().__init__()\n",
    "        self.g_model = g_model.cuda()\n",
    "        self.d_model = d_model.cuda()\n",
    "\n",
    "        self._loss_fn_ce = nn.CrossEntropyLoss()\n",
    "        self._loss_fn_mse = nn.MSELoss()\n",
    "        self._optimizer_g_model = torch.optim.Adam(\n",
    "            g_model.parameters(),\n",
    "            lr=RECEIVED_PARAMS['g_lr'],\n",
    "            weight_decay=RECEIVED_PARAMS['weight_decay'])\n",
    "        self._optimizer_d_model = torch.optim.Adam(\n",
    "            d_model.parameters(),\n",
    "            lr=RECEIVED_PARAMS['d_lr'],\n",
    "            weight_decay=RECEIVED_PARAMS['weight_decay'])\n",
    "\n",
    "        self._trainer_kwargs = trainer_kwargs\n",
    "\n",
    "        eeg_dataset = dataset\n",
    "        train_dataset, val_dataset = train_test_split(eeg_dataset)\n",
    "        train_dataloader = DataLoader(train_dataset,\n",
    "                                      batch_size=64,\n",
    "                                      shuffle=True,\n",
    "                                      drop_last=False)\n",
    "\n",
    "        self._train_dataloader = train_dataloader\n",
    "\n",
    "    def _accuracy(self, input, target):  # pylint: disable=redefined-builtin\n",
    "        _, predict = torch.max(input.data, 1)\n",
    "        correct = predict.eq(target.data).cpu().sum().item()\n",
    "        return correct / input.size(0)\n",
    "\n",
    "    def training_step_g_model(self, batch, batch_idx, augment_fn=random_mask):\n",
    "        self._optimizer_g_model.zero_grad()\n",
    "\n",
    "        for p in self.d_model.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        x, y = batch\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "\n",
    "        aug_x, ratio = random_mask(x)\n",
    "        pred_x = self.g_model(aug_x)\n",
    "        loss = -self.d_model(pred_x).mean()\n",
    "\n",
    "        loss.backward()\n",
    "        self._optimizer_g_model.step()\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def training_step_d_model(self, batch, batch_idx, augment_fn=random_mask):\n",
    "        self._optimizer_d_model.zero_grad()\n",
    "\n",
    "        for p in self.d_model.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "        x, y = batch\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "\n",
    "        aug_x, ratio = random_mask(x)\n",
    "        pred_x = self.g_model(aug_x).detach()\n",
    "\n",
    "        loss = self.d_model(pred_x).mean() - self.d_model(x).mean()\n",
    "        loss += RECEIVED_PARAMS['weight_gp'] * gradient_penalty(\n",
    "            self.d_model, x, pred_x)\n",
    "\n",
    "        if batch_idx % 5 == 0:\n",
    "            loss.backward()\n",
    "            self._optimizer_d_model.step()\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def _train(self, epoch_idx=-1):\n",
    "        \"\"\"\n",
    "        å•ç‹¬æ˜¾ç¤ºæ¯ä¸ª epoch çš„è®­ç»ƒè¿›åº¦æ¡ï¼Œå¹¶åŠ¨æ€æ›´æ–° G å’Œ D çš„æŸå¤±ã€‚\n",
    "        \"\"\"\n",
    "        pbar = tqdm(total=len(self._train_dataloader), desc=f\"[TRAIN] Epoch {epoch_idx}\")\n",
    "        for i, batch in enumerate(self._train_dataloader):\n",
    "            # è·å– D æ¨¡å‹çš„æŸå¤±\n",
    "            loss_d_model = self.training_step_d_model(batch, i)\n",
    "            # è·å– G æ¨¡å‹çš„æŸå¤±\n",
    "            loss_g_model = self.training_step_g_model(batch, i)\n",
    "\n",
    "            # æ›´æ–°è¿›åº¦æ¡\n",
    "            pbar.update(1)\n",
    "            pbar.set_postfix(\n",
    "                ordered_dict={\n",
    "                    'loss_g_model': f'{loss_g_model.item():.3f}',\n",
    "                    'loss_d_model': f'{loss_d_model.item():.3f}'\n",
    "                }\n",
    "            )\n",
    "        pbar.close()\n",
    "        \n",
    "    def fit(self) -> None:\n",
    "        for i in range(self._trainer_kwargs['max_epochs']):\n",
    "            self._train(i + 1)\n",
    "\n",
    "    def save(self, param_path):\n",
    "        torch.save(\n",
    "            {\n",
    "                'g_model': self.g_model.state_dict(),\n",
    "                'd_model': self.d_model.state_dict()\n",
    "            }, param_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, num_classes, in_channels=4):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.layer1 = nn.Conv2d(in_channels,\n",
    "                                256,\n",
    "                                kernel_size=3,\n",
    "                                stride=1,\n",
    "                                padding=1,\n",
    "                                bias=True)\n",
    "        self.layer2 = nn.Conv2d(256,\n",
    "                                128,\n",
    "                                kernel_size=5,\n",
    "                                stride=1,\n",
    "                                padding=2,\n",
    "                                bias=True)\n",
    "        self.layer3 = nn.Conv2d(128,\n",
    "                                64,\n",
    "                                kernel_size=5,\n",
    "                                stride=1,\n",
    "                                padding=2,\n",
    "                                bias=True)\n",
    "        self.layer4 = SeparableConv2d(64,\n",
    "                                      32,\n",
    "                                      kernel_size=5,\n",
    "                                      stride=1,\n",
    "                                      padding=2,\n",
    "                                      bias=True)\n",
    "        self.layer5 = InceptionConv2d(32, 16)\n",
    "        self.drop = nn.Sequential(nn.Dropout(), nn.SELU())\n",
    "        self.fc1 = nn.Sequential(nn.Linear(9 * 9 * 16, 1024, bias=True),\n",
    "                                 nn.SELU())\n",
    "        self.fc2 = nn.Linear(1024, num_classes, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.drop(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.layer5(out)\n",
    "        out = self.drop(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        feat = self.fc1(out)\n",
    "        out = self.fc2(feat)\n",
    "        return out, feat\n",
    "\n",
    "\n",
    "c_model = Classifier(num_classes=2, in_channels=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import SwinTransformer_D\n",
    "c_model = SwinTransformer_D(in_chans=128,\n",
    "                            num_classes=2,\n",
    "                            embed_dim=96,\n",
    "                            depths=(2, 2, 4, 2),\n",
    "                            num_heads=(2, 2, 4, 6),\n",
    "                            visual_mode=True\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/autodl-tmp/conda/envs/law/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:613: UserWarning: Checkpoint directory /root/autodl-tmp/.autodl/kinlaw/GANSER/mycode/checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/root/autodl-tmp/conda/envs/law/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 128 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 24.67it/s, loss=0.79, train_loss=0.740, train_accuracy=0.333] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/autodl-tmp/conda/envs/law/lib/python3.8/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('train_loss', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "  rank_zero_warn(\n",
      "/root/autodl-tmp/conda/envs/law/lib/python3.8/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('train_accuracy', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "  rank_zero_warn(\n",
      "[2025-02-11 14:33:21] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.790 train_accuracy: 0.500 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 24.68it/s, loss=0.673, train_loss=0.619, train_accuracy=0.667]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-02-11 14:33:22] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.646 train_accuracy: 0.598 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 25.02it/s, loss=0.607, train_loss=0.599, train_accuracy=0.667]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-02-11 14:33:23] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.585 train_accuracy: 0.735 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 24.94it/s, loss=0.536, train_loss=0.559, train_accuracy=0.750]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-02-11 14:33:24] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.521 train_accuracy: 0.779 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 25.00it/s, loss=0.47, train_loss=0.525, train_accuracy=0.583] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-02-11 14:33:25] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.454 train_accuracy: 0.838 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 25.36it/s, loss=0.417, train_loss=0.252, train_accuracy=0.917]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-02-11 14:33:26] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.387 train_accuracy: 0.814 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 25.51it/s, loss=0.327, train_loss=0.548, train_accuracy=0.667]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-02-11 14:33:27] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.302 train_accuracy: 0.882 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 25.63it/s, loss=0.238, train_loss=0.450, train_accuracy=0.833]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-02-11 14:33:28] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.213 train_accuracy: 0.926 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 25.69it/s, loss=0.179, train_loss=0.250, train_accuracy=0.833] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-02-11 14:33:29] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.165 train_accuracy: 0.941 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 25.71it/s, loss=0.132, train_loss=0.171, train_accuracy=0.917] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-02-11 14:33:30] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.107 train_accuracy: 0.975 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 25.73it/s, loss=0.0849, train_loss=0.114, train_accuracy=0.917] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-02-11 14:33:31] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.068 train_accuracy: 0.995 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 24.16it/s, loss=0.0518, train_loss=0.0488, train_accuracy=1.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-02-11 14:33:32] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.035 train_accuracy: 1.000 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 24.53it/s, loss=0.0279, train_loss=0.0094, train_accuracy=1.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-02-11 14:33:33] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.025 train_accuracy: 1.000 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 24.66it/s, loss=0.0212, train_loss=0.0164, train_accuracy=1.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-02-11 14:33:34] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.021 train_accuracy: 0.995 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 24.63it/s, loss=0.0205, train_loss=0.0284, train_accuracy=1.000] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-02-11 14:33:35] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.017 train_accuracy: 1.000 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 24.97it/s, loss=0.0121, train_loss=0.00458, train_accuracy=1.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-02-11 14:33:36] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.010 train_accuracy: 1.000 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 25.15it/s, loss=0.00865, train_loss=0.00407, train_accuracy=1.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-02-11 14:33:37] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.007 train_accuracy: 1.000 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 25.49it/s, loss=0.00718, train_loss=0.022, train_accuracy=1.000]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-02-11 14:33:38] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.007 train_accuracy: 1.000 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 23.68it/s, loss=0.00802, train_loss=0.00277, train_accuracy=1.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-02-11 14:33:39] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.008 train_accuracy: 1.000 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 24.70it/s, loss=0.0065, train_loss=0.0025, train_accuracy=1.000]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-02-11 14:33:39] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.006 train_accuracy: 1.000 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 24.63it/s, loss=0.00497, train_loss=0.00675, train_accuracy=1.000] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-02-11 14:33:40] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.005 train_accuracy: 1.000 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 25.34it/s, loss=0.00494, train_loss=0.00439, train_accuracy=1.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-02-11 14:33:41] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.005 train_accuracy: 1.000 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 25.13it/s, loss=0.00409, train_loss=0.00302, train_accuracy=1.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-02-11 14:33:42] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.004 train_accuracy: 1.000 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 25.44it/s, loss=0.00437, train_loss=0.00228, train_accuracy=1.000] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-02-11 14:33:43] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.004 train_accuracy: 1.000 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 24.99it/s, loss=0.0046, train_loss=0.00303, train_accuracy=1.000] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-02-11 14:33:44] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.005 train_accuracy: 1.000 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 25.16it/s, loss=0.00483, train_loss=0.000775, train_accuracy=1.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-02-11 14:33:45] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.004 train_accuracy: 1.000 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 24.72it/s, loss=0.00274, train_loss=0.00158, train_accuracy=1.000] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-02-11 14:33:46] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.003 train_accuracy: 1.000 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 25.42it/s, loss=0.00278, train_loss=0.00537, train_accuracy=1.000] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-02-11 14:33:47] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.003 train_accuracy: 1.000 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 24.74it/s, loss=0.00206, train_loss=0.000387, train_accuracy=1.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-02-11 14:33:48] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.001 train_accuracy: 1.000 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 24.91it/s, loss=0.0012, train_loss=0.00254, train_accuracy=1.000]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-02-11 14:33:49] INFO (torcheeg/MainThread) \n",
      "[Train] train_loss: 0.001 train_accuracy: 1.000 \n",
      "\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 13.42it/s, loss=0.0012, train_loss=0.00254, train_accuracy=1.000]\n"
     ]
    }
   ],
   "source": [
    "from classifier import  ClassifierTrainer\n",
    "\n",
    "train_dataset, val_dataset = train_test_split(sub_dataset)\n",
    "trainer = ClassifierTrainer(model=c_model,\n",
    "                            num_classes=2,\n",
    "                            lr=RECEIVED_PARAMS['c_lr'],\n",
    "                            weight_decay=1e-5,\n",
    "                            metrics=[\"accuracy\"],\n",
    "                            accelerator=\"gpu\")\n",
    "train_dataloader = DataLoader(train_dataset,\n",
    "                              batch_size=16,\n",
    "                              shuffle=True,\n",
    "                              drop_last=False)\n",
    "val_dataloader = DataLoader(val_dataset,\n",
    "                            batch_size=16,\n",
    "                            shuffle=False,\n",
    "                            drop_last=False)\n",
    "\n",
    "trainer.fit(train_dataloader,\n",
    "            val_dataloader,\n",
    "            max_epochs=30,\n",
    "            enable_model_summary=False,\n",
    "            limit_val_batches=0.0)\n",
    "trainer.save('./parameters/' + 'cross_validation_backbone.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/root/autodl-tmp/conda/envs/law/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 128 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 94.00it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-02-11 14:33:53] INFO (torcheeg/MainThread) \n",
      "[Test] test_loss: 2.402 test_accuracy: 0.577 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 83.63it/s]\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "       Test metric             DataLoader 0\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "      test_accuracy         0.5769230723381042\n",
      "        test_loss           2.4023923873901367\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "0.5769230723381042\n"
     ]
    }
   ],
   "source": [
    "val_dataloader = DataLoader(val_dataset,\n",
    "                            batch_size=16,\n",
    "                            shuffle=False,\n",
    "                            drop_last=False)\n",
    "\n",
    "test_result = trainer.test(val_dataloader,\n",
    "                            enable_progress_bar=True,\n",
    "                            enable_model_summary=True)[0]\n",
    "# training_metrics.append(training_result[\"test_accuracy\"])\n",
    "print(test_result[\"test_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00,  8.35it/s, loss_c_model=0.684]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 27.80it/s, loss_c_model=0.523]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.53125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 27.93it/s, loss_c_model=0.612]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.84375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 27.85it/s, loss_c_model=0.365]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.84375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.14it/s, loss_c_model=0.331]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.84375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.62it/s, loss_c_model=0.327]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.84375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.81it/s, loss_c_model=0.244]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.16it/s, loss_c_model=0.089]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.84375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.83it/s, loss_c_model=0.186]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.78125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.22it/s, loss_c_model=0.064]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.61it/s, loss_c_model=0.038]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.78125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.01it/s, loss_c_model=0.015]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.27it/s, loss_c_model=0.004]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 27.33it/s, loss_c_model=0.008]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.44it/s, loss_c_model=0.005]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 16: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.77it/s, loss_c_model=0.007]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 17: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.37it/s, loss_c_model=0.009]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 18: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.36it/s, loss_c_model=0.004]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 19: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 27.39it/s, loss_c_model=0.007]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.37it/s, loss_c_model=0.002]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 21: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.51it/s, loss_c_model=0.002]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 22: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.51it/s, loss_c_model=0.010]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 23: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.77it/s, loss_c_model=0.003]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 24: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.56it/s, loss_c_model=0.001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.82it/s, loss_c_model=0.003]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 26: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.79it/s, loss_c_model=0.002]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 27: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.70it/s, loss_c_model=0.001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 28: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.77it/s, loss_c_model=0.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 29: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.93it/s, loss_c_model=0.001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.72it/s, loss_c_model=0.001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 31: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.96it/s, loss_c_model=0.001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 29.09it/s, loss_c_model=0.001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 33: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.89it/s, loss_c_model=0.001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 34: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.63it/s, loss_c_model=0.002]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.97it/s, loss_c_model=0.003]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 36: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.98it/s, loss_c_model=0.003]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 37: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.55it/s, loss_c_model=0.003]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 38: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.98it/s, loss_c_model=0.001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 39: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 29.00it/s, loss_c_model=0.001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 40: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 27.79it/s, loss_c_model=0.001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 41: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.98it/s, loss_c_model=0.001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 42: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 29.02it/s, loss_c_model=0.001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 43: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 29.01it/s, loss_c_model=0.001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 44: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.88it/s, loss_c_model=0.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 45: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 29.00it/s, loss_c_model=0.001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 46: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.72it/s, loss_c_model=0.001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 47: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.93it/s, loss_c_model=0.001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 48: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 29.03it/s, loss_c_model=0.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 49: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 29.05it/s, loss_c_model=0.001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 29.07it/s, loss_c_model=0.002]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 51: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.78it/s, loss_c_model=0.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 52: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.90it/s, loss_c_model=0.001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 53: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.10it/s, loss_c_model=0.001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 54: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.96it/s, loss_c_model=0.003]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 55: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 29.08it/s, loss_c_model=0.001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 56: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.95it/s, loss_c_model=0.001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 57: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 29.08it/s, loss_c_model=0.001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 58: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.35it/s, loss_c_model=0.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 59: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.94it/s, loss_c_model=0.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.73it/s, loss_c_model=0.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 61: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.06it/s, loss_c_model=0.002]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 62: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 29.01it/s, loss_c_model=0.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 63: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 29.23it/s, loss_c_model=0.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 64: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.79it/s, loss_c_model=0.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 65: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.47it/s, loss_c_model=0.001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 66: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.79it/s, loss_c_model=0.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 67: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.82it/s, loss_c_model=0.001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 68: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 27.76it/s, loss_c_model=0.001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 69: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 27.64it/s, loss_c_model=0.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 70: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.34it/s, loss_c_model=0.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 71: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 27.87it/s, loss_c_model=0.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 72: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.01it/s, loss_c_model=0.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 73: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.62it/s, loss_c_model=0.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 74: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.77it/s, loss_c_model=0.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 75: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 27.78it/s, loss_c_model=0.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 76: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.77it/s, loss_c_model=0.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 77: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.93it/s, loss_c_model=0.001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 78: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.53it/s, loss_c_model=0.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 79: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.52it/s, loss_c_model=0.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 80: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 28.95it/s, loss_c_model=0.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8125\n"
     ]
    }
   ],
   "source": [
    "class CTrainer():\n",
    "    def __init__(self, c_model, trainer_kwargs={'max_epochs': 10}):\n",
    "        super().__init__()\n",
    "        self.c_model = c_model.cuda()\n",
    "\n",
    "        self._loss_fn_ce = nn.CrossEntropyLoss()\n",
    "        self._optimizer_c_model = torch.optim.Adam(c_model.parameters(),\n",
    "                                                   lr=RECEIVED_PARAMS['c_lr'],\n",
    "                                                   weight_decay=0.0005)\n",
    "        self._trainer_kwargs = trainer_kwargs\n",
    "\n",
    "        eeg_dataset = dataset\n",
    "        train_dataset, val_dataset = train_test_split(eeg_dataset)\n",
    "        train_dataloader = DataLoader(train_dataset,\n",
    "                                      batch_size=16,\n",
    "                                      shuffle=True,\n",
    "                                      drop_last=False)\n",
    "        val_dataloader = DataLoader(val_dataset,\n",
    "                                    batch_size=16,\n",
    "                                    shuffle=False,\n",
    "                                    drop_last=False)\n",
    "\n",
    "        self._train_dataloader = train_dataloader\n",
    "        self._val_dataloader = val_dataloader\n",
    "\n",
    "    def _accuracy(self, input, target):  # pylint: disable=redefined-builtin\n",
    "        _, predict = torch.max(input.data, 1)\n",
    "        correct = predict.eq(target.data).cpu().sum().item()\n",
    "        return correct / input.size(0)\n",
    "\n",
    "    def training_step_c_model(self, batch, batch_idx):\n",
    "        for p in self.c_model.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "        self._optimizer_c_model.zero_grad()\n",
    "\n",
    "        x, y = batch\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "\n",
    "        y_hat, x_feat = self.c_model(x)\n",
    "        loss = self._loss_fn_ce(y_hat, y)\n",
    "\n",
    "        loss.backward()\n",
    "        self._optimizer_c_model.step()\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = self.validation_step_before_model(batch, batch_idx)\n",
    "        y_hat, x_feat = self.c_model(x)\n",
    "        return (y_hat.detach().cpu(), y.detach().cpu())\n",
    "\n",
    "    def validation_step_before_model(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "        return x, y\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        # We might need dict metrics in future?\n",
    "        y_hat, y = zip(*outputs)\n",
    "        y_hat = torch.cat(y_hat, dim=0)\n",
    "        y = torch.cat(y, dim=0)\n",
    "        avg_acc = self._accuracy(y_hat, y)\n",
    "        print(\"acc:\", avg_acc)\n",
    "        # logger.info('[VAL] Average ACC at epoch end is {}'.format(avg_acc))\n",
    "        # return {'val_acc': avg_acc}\n",
    "\n",
    "    def _validate(self, epoch_idx=-1):\n",
    "        validation_outputs = []\n",
    "        for i, batch in enumerate(self._val_dataloader):\n",
    "            validation_outputs.append(self.validation_step(batch, i))\n",
    "        return self.validation_epoch_end(validation_outputs)\n",
    "\n",
    "    def _train(self, epoch_idx=-1):\n",
    "        \"\"\"\n",
    "        å•ç‹¬æ˜¾ç¤ºæ¯ä¸ª epoch çš„è®­ç»ƒè¿›åº¦æ¡ã€‚\n",
    "        \"\"\"\n",
    "        pbar = tqdm(total=len(self._train_dataloader), desc=f\"[TRAIN] Epoch {epoch_idx}\")\n",
    "        for i, batch in enumerate(self._train_dataloader):\n",
    "            loss_c_model = self.training_step_c_model(batch, i)\n",
    "            pbar.update(1)\n",
    "            # æ›´æ–°è¿›åº¦æ¡çš„åç¼€ä¿¡æ¯\n",
    "            pbar.set_postfix(ordered_dict={'loss_c_model': f'{loss_c_model.item():.3f}'})\n",
    "        pbar.close()\n",
    "\n",
    "    def fit(self) -> None:\n",
    "        \"\"\"\n",
    "        æŒ‰ç…§æ¯ä¸ª epoch å•ç‹¬åˆ›å»ºè®­ç»ƒå’ŒéªŒè¯è¿›åº¦æ¡ã€‚\n",
    "        \"\"\"\n",
    "        for epoch_idx in range(self._trainer_kwargs['max_epochs']):\n",
    "            self._train(epoch_idx + 1)\n",
    "            self._validate(epoch_idx + 1)\n",
    "\n",
    "        # logger.info('[VAL] Final ACC at experiment end is {}'.format(\n",
    "        #     self._validate()['val_acc']))\n",
    "\n",
    "    def save(self, param_path):\n",
    "        torch.save({\n",
    "            'c_model': self.c_model.state_dict(),\n",
    "        }, param_path)\n",
    "\n",
    "\n",
    "trainer = CTrainer(c_model, trainer_kwargs={'max_epochs': 80})\n",
    "trainer.fit()\n",
    "trainer.save('./parameters/' + 'cross_validation_backbone.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import SwinTransformer, SwinTransformer_D\n",
    "\n",
    "c_model = SwinTransformer_D(in_chans=128,\n",
    "                            num_classes=2,\n",
    "                            embed_dim=96,\n",
    "                            depths=(2, 2, 4, 2),\n",
    "                            num_heads=(2, 2, 4, 6),\n",
    "                            visual_mode=True\n",
    "                            )\n",
    "d_model = SwinTransformer(in_chans=128,\n",
    "                          num_classes=2,\n",
    "                          embed_dim=96,\n",
    "                          depths=(2, 2, 4, 2),\n",
    "                          num_heads=(2, 2, 4, 6),\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 128, 9, 9])\n",
      "tensor([[ 0.0711, -0.0519],\n",
      "        [-0.0337, -0.1579]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# æ¨¡æ‹Ÿè¾“å…¥\n",
    "import torch\n",
    "input_tensor = torch.randn(2, 128, 9, 9)  # [batch, 1, 128, 7, 5]\n",
    "output = d_model(input_tensor)\n",
    "\n",
    "print(\"Input shape:\", input_tensor.shape)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.38it/s, loss_c_model=0.647]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 1] Validation Accuracy: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.76it/s, loss_c_model=0.508]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 2] Validation Accuracy: 0.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.59it/s, loss_c_model=0.396]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 3] Validation Accuracy: 0.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.79it/s, loss_c_model=0.324]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 4] Validation Accuracy: 0.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.01it/s, loss_c_model=0.254]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 5] Validation Accuracy: 0.844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.04it/s, loss_c_model=0.190]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 6] Validation Accuracy: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.06it/s, loss_c_model=0.159]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 7] Validation Accuracy: 0.781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.09it/s, loss_c_model=0.140]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 8] Validation Accuracy: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.86it/s, loss_c_model=0.132]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 9] Validation Accuracy: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.81it/s, loss_c_model=0.141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 10] Validation Accuracy: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.35it/s, loss_c_model=0.134]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 11] Validation Accuracy: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.82it/s, loss_c_model=0.112]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 12] Validation Accuracy: 0.781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.97it/s, loss_c_model=0.111]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 13] Validation Accuracy: 0.781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.06it/s, loss_c_model=0.102]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 14] Validation Accuracy: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.06it/s, loss_c_model=0.105]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 15] Validation Accuracy: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 16: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.56it/s, loss_c_model=0.087]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 16] Validation Accuracy: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 17: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.86it/s, loss_c_model=0.088]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 17] Validation Accuracy: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 18: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.01it/s, loss_c_model=0.079]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 18] Validation Accuracy: 0.781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 19: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.04it/s, loss_c_model=0.073]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 19] Validation Accuracy: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.00it/s, loss_c_model=0.078]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 20] Validation Accuracy: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 21: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.00it/s, loss_c_model=0.070]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 21] Validation Accuracy: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 22: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.88it/s, loss_c_model=0.084]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 22] Validation Accuracy: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 23: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.50it/s, loss_c_model=0.066]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 23] Validation Accuracy: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 24: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.60it/s, loss_c_model=0.065]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 24] Validation Accuracy: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.17it/s, loss_c_model=0.069]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 25] Validation Accuracy: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 26: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.48it/s, loss_c_model=0.063]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 26] Validation Accuracy: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 27: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.00it/s, loss_c_model=0.062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 27] Validation Accuracy: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 28: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.25it/s, loss_c_model=0.067]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 28] Validation Accuracy: 0.781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 29: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.75it/s, loss_c_model=0.060]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 29] Validation Accuracy: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.03it/s, loss_c_model=0.063]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 30] Validation Accuracy: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 31: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.01it/s, loss_c_model=0.061]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 31] Validation Accuracy: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.04it/s, loss_c_model=0.056]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 32] Validation Accuracy: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 33: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.98it/s, loss_c_model=0.059]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 33] Validation Accuracy: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 34: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.29it/s, loss_c_model=0.055]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 34] Validation Accuracy: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.41it/s, loss_c_model=0.057]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 35] Validation Accuracy: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 36: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.47it/s, loss_c_model=0.055]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 36] Validation Accuracy: 0.781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 37: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.96it/s, loss_c_model=0.055]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 37] Validation Accuracy: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 38: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.94it/s, loss_c_model=0.056]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 38] Validation Accuracy: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 39: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.65it/s, loss_c_model=0.050]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 39] Validation Accuracy: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 40: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.57it/s, loss_c_model=0.051]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 40] Validation Accuracy: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 41: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.86it/s, loss_c_model=0.049]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 41] Validation Accuracy: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 42: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.89it/s, loss_c_model=0.049]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 42] Validation Accuracy: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 43: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.89it/s, loss_c_model=0.048]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 43] Validation Accuracy: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 44: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.96it/s, loss_c_model=0.046]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 44] Validation Accuracy: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 45: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.35it/s, loss_c_model=0.048]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 45] Validation Accuracy: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 46: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.81it/s, loss_c_model=0.047]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 46] Validation Accuracy: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 47: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.87it/s, loss_c_model=0.049]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 47] Validation Accuracy: 0.781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 48: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.90it/s, loss_c_model=0.043]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 48] Validation Accuracy: 0.781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 49: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.57it/s, loss_c_model=0.048]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 49] Validation Accuracy: 0.844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.27it/s, loss_c_model=0.047]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 50] Validation Accuracy: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 51: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.33it/s, loss_c_model=0.044]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 51] Validation Accuracy: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 52: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 11.32it/s, loss_c_model=0.042]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 52] Validation Accuracy: 0.781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 53: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.35it/s, loss_c_model=0.041]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 53] Validation Accuracy: 0.750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 54: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.88it/s, loss_c_model=0.042]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 54] Validation Accuracy: 0.781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 55: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.93it/s, loss_c_model=0.043]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 55] Validation Accuracy: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 56: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.74it/s, loss_c_model=0.042]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 56] Validation Accuracy: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 57: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.81it/s, loss_c_model=0.041]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 57] Validation Accuracy: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 58: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.91it/s, loss_c_model=0.043]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 58] Validation Accuracy: 0.781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 59: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.89it/s, loss_c_model=0.043]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 59] Validation Accuracy: 0.781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.03it/s, loss_c_model=0.040]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 60] Validation Accuracy: 0.750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 61: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.06it/s, loss_c_model=0.042]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 61] Validation Accuracy: 0.781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 62: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.04it/s, loss_c_model=0.041]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 62] Validation Accuracy: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 63: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.91it/s, loss_c_model=0.043]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 63] Validation Accuracy: 0.781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 64: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.64it/s, loss_c_model=0.038]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 64] Validation Accuracy: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 65: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.99it/s, loss_c_model=0.038]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 65] Validation Accuracy: 0.781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 66: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.97it/s, loss_c_model=0.039]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 66] Validation Accuracy: 0.750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 67: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.55it/s, loss_c_model=0.041]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 67] Validation Accuracy: 0.781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 68: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.84it/s, loss_c_model=0.041]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 68] Validation Accuracy: 0.750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 69: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.01it/s, loss_c_model=0.038]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 69] Validation Accuracy: 0.781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 70: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.93it/s, loss_c_model=0.039]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 70] Validation Accuracy: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 71: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.00it/s, loss_c_model=0.038]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 71] Validation Accuracy: 0.750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 72: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.04it/s, loss_c_model=0.038]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 72] Validation Accuracy: 0.750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 73: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.87it/s, loss_c_model=0.038]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 73] Validation Accuracy: 0.781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 74: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.95it/s, loss_c_model=0.036]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 74] Validation Accuracy: 0.781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 75: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.02it/s, loss_c_model=0.035]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 75] Validation Accuracy: 0.750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 76: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.61it/s, loss_c_model=0.036]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 76] Validation Accuracy: 0.750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 77: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.96it/s, loss_c_model=0.035]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 77] Validation Accuracy: 0.719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 78: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.89it/s, loss_c_model=0.036]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 78] Validation Accuracy: 0.719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 79: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.68it/s, loss_c_model=0.035]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 79] Validation Accuracy: 0.750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 80: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.97it/s, loss_c_model=0.037]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 80] Validation Accuracy: 0.750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 81: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.91it/s, loss_c_model=0.036]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 81] Validation Accuracy: 0.781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 82: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.93it/s, loss_c_model=0.035]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 82] Validation Accuracy: 0.750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 83: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.77it/s, loss_c_model=0.035]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 83] Validation Accuracy: 0.719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 84: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.79it/s, loss_c_model=0.034]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 84] Validation Accuracy: 0.719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 85: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.97it/s, loss_c_model=0.035]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 85] Validation Accuracy: 0.719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 86: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.00it/s, loss_c_model=0.032]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 86] Validation Accuracy: 0.719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 87: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.01it/s, loss_c_model=0.035]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 87] Validation Accuracy: 0.750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 88: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.66it/s, loss_c_model=0.035]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 88] Validation Accuracy: 0.750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 89: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.04it/s, loss_c_model=0.033]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 89] Validation Accuracy: 0.719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 90: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.81it/s, loss_c_model=0.032]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 90] Validation Accuracy: 0.750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 91: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.93it/s, loss_c_model=0.038]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 91] Validation Accuracy: 0.719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 92: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.04it/s, loss_c_model=0.037]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 92] Validation Accuracy: 0.750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 93: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.06it/s, loss_c_model=0.033]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 93] Validation Accuracy: 0.750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 94: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.03it/s, loss_c_model=0.034]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 94] Validation Accuracy: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.05it/s, loss_c_model=0.035]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 95] Validation Accuracy: 0.719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 96: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.92it/s, loss_c_model=0.033]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 96] Validation Accuracy: 0.719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 97: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.05it/s, loss_c_model=0.032]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 97] Validation Accuracy: 0.719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 98: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.02it/s, loss_c_model=0.034]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 98] Validation Accuracy: 0.750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 99: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.07it/s, loss_c_model=0.033]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 99] Validation Accuracy: 0.719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.47it/s, loss_c_model=0.033]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 100] Validation Accuracy: 0.719\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GCTrainer():\n",
    "    def __init__(self, c_model, g_model, trainer_kwargs={'max_epochs': 10}):\n",
    "        super().__init__()\n",
    "        self.c_model = c_model.cuda()\n",
    "        self.g_model = g_model.cuda()\n",
    "\n",
    "        self._loss_fn_ce = nn.CrossEntropyLoss()\n",
    "        self._loss_fn_mse = nn.MSELoss()\n",
    "        self._optimizer_c_model = torch.optim.Adam(c_model.parameters(),\n",
    "                                                   lr=RECEIVED_PARAMS['c_lr'],\n",
    "                                                   weight_decay=0.0005)\n",
    "\n",
    "        self._trainer_kwargs = trainer_kwargs\n",
    "\n",
    "        eeg_dataset = dataset\n",
    "        train_dataset, val_dataset = train_test_split(eeg_dataset)\n",
    "        train_dataloader = DataLoader(train_dataset,\n",
    "                                      batch_size=64,\n",
    "                                      shuffle=True,\n",
    "                                      drop_last=False)\n",
    "        val_dataloader = DataLoader(val_dataset,\n",
    "                                    batch_size=64,\n",
    "                                    shuffle=False,\n",
    "                                    drop_last=False)\n",
    "\n",
    "        self._train_dataloader = train_dataloader\n",
    "        self._val_dataloader = val_dataloader\n",
    "\n",
    "    def _accuracy(self, input, target):  # pylint: disable=redefined-builtin\n",
    "        _, predict = torch.max(input.data, 1)\n",
    "        correct = predict.eq(target.data).cpu().sum().item()\n",
    "        return correct / input.size(0)\n",
    "\n",
    "    def training_step_c_model(self, batch, batch_idx):\n",
    "        for p in self.c_model.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "        self._optimizer_c_model.zero_grad()\n",
    "\n",
    "        x, y = batch\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "\n",
    "        y_hat, x_feat = self.c_model(x)\n",
    "        loss = self._loss_fn_ce(y_hat, y)\n",
    "\n",
    "        aug_x, ratio = random_mask(x)\n",
    "        aug_x = self.g_model(aug_x).detach()\n",
    "        aug_y_hat, aug_x_feat = self.c_model(aug_x)\n",
    "\n",
    "        loss += RECEIVED_PARAMS['weight_ssl'] * (\n",
    "            (1 - ratio).squeeze() * F.mse_loss(\n",
    "                x_feat, aug_x_feat, reduction='none').mean(dim=-1)).mean()\n",
    "\n",
    "        loss.backward()\n",
    "        self._optimizer_c_model.step()\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = self.validation_step_before_model(batch, batch_idx)\n",
    "        y_hat, x_feat = self.c_model(x)\n",
    "        return (y_hat.detach().cpu(), y.detach().cpu())\n",
    "\n",
    "    def validation_step_before_model(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "        return x, y\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        # We might need dict metrics in future?\n",
    "        y_hat, y = zip(*outputs)\n",
    "        y_hat = torch.cat(y_hat, dim=0)\n",
    "        y = torch.cat(y, dim=0)\n",
    "        avg_acc = self._accuracy(y_hat, y)\n",
    "        # logger.info('[VAL] Average ACC at epoch end is {}'.format(avg_acc))\n",
    "        return {'val_acc': avg_acc}\n",
    "\n",
    "    def _validate(self, epoch_idx=-1):\n",
    "        validation_outputs = []\n",
    "        for i, batch in enumerate(self._val_dataloader):\n",
    "            validation_outputs.append(self.validation_step(batch, i))\n",
    "        return self.validation_epoch_end(validation_outputs)\n",
    "\n",
    "    def _train(self, epoch_idx=-1):\n",
    "        \"\"\"\n",
    "        å•ç‹¬æ˜¾ç¤ºæ¯ä¸ª epoch çš„è®­ç»ƒè¿›åº¦æ¡ã€‚\n",
    "        \"\"\"\n",
    "        pbar = tqdm(total=len(self._train_dataloader), desc=f\"[TRAIN] Epoch {epoch_idx}\")\n",
    "        for i, batch in enumerate(self._train_dataloader):\n",
    "            loss_c_model = self.training_step_c_model(batch, i)\n",
    "            pbar.update(1)\n",
    "            # æ›´æ–°è¿›åº¦æ¡çš„åç¼€ä¿¡æ¯\n",
    "            pbar.set_postfix(ordered_dict={'loss_c_model': f'{loss_c_model.item():.3f}'})\n",
    "        pbar.close()\n",
    "\n",
    "    def fit(self) -> None:\n",
    "        \"\"\"\n",
    "        æŒ‰ç…§æ¯ä¸ª epoch å•ç‹¬åˆ›å»ºè®­ç»ƒå’ŒéªŒè¯è¿›åº¦æ¡ã€‚\n",
    "        \"\"\"\n",
    "        for epoch_idx in range(self._trainer_kwargs['max_epochs']):\n",
    "            self._train(epoch_idx + 1)\n",
    "                # éªŒè¯è¿‡ç¨‹å¹¶è·å–éªŒè¯ç»“æœ\n",
    "            val_metrics = self._validate(epoch_idx + 1)\n",
    "            val_acc = val_metrics['val_acc']\n",
    "            \n",
    "            # æ‰“å°éªŒè¯å‡†ç¡®ç‡\n",
    "            print(f\"[EPOCH {epoch_idx + 1}] Validation Accuracy: {val_acc:.3f}\")\n",
    "\n",
    "    def save(self, param_path):\n",
    "        torch.save({\n",
    "            'c_model': trainer.c_model.state_dict(),\n",
    "        }, param_path)\n",
    "\n",
    "    def load(self):\n",
    "        gan_model_state_dict = torch.load(\n",
    "            './parameters/cross_validation_proposed_pretrain.pth')\n",
    "        self.g_model.load_state_dict(gan_model_state_dict['g_model'])\n",
    "\n",
    "        if os.path.exists('./parameters/cross_validation_backbone' + '.pth'):\n",
    "            c_model_state_dict = torch.load(\n",
    "                './parameters/cross_validation_backbone'  +\n",
    "                '.pth')\n",
    "            self.c_model.load_state_dict(c_model_state_dict['c_model'])\n",
    "\n",
    "\n",
    "trainer = GCTrainer(c_model,\n",
    "                  g_model,\n",
    "                  trainer_kwargs={'max_epochs': 100})\n",
    "trainer.load()\n",
    "trainer.fit()\n",
    "trainer.save('./parameters/' +  'cross_validation_finetune.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SwinTransformer(\n",
      "  (patch_embed): PatchEmbed(\n",
      "    (proj): Conv2d(128, 96, kernel_size=(4, 4), stride=(4, 4))\n",
      "    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "  (layers): ModuleList(\n",
      "    (0): BasicLayer(\n",
      "      (blocks): ModuleList(\n",
      "        (0): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath()\n",
      "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (downsample): PatchMerging(\n",
      "        (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
      "        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicLayer(\n",
      "      (blocks): ModuleList(\n",
      "        (0): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath()\n",
      "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath()\n",
      "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (downsample): PatchMerging(\n",
      "        (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (2): BasicLayer(\n",
      "      (blocks): ModuleList(\n",
      "        (0): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (downsample): PatchMerging(\n",
      "        (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
      "        (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (3): BasicLayer(\n",
      "      (blocks): ModuleList(\n",
      "        (0): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath()\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath()\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
      "  (head): Linear(in_features=768, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_model = Generator(in_channels=128, out_channels=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.62it/s, loss_g_model=-3.194, loss_d_model=0.451]\n",
      "[TRAIN] Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.83it/s, loss_g_model=-3.115, loss_d_model=0.369]\n",
      "[TRAIN] Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.59it/s, loss_g_model=-3.049, loss_d_model=0.309]\n",
      "[TRAIN] Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.74it/s, loss_g_model=-2.993, loss_d_model=0.308]\n",
      "[TRAIN] Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.61it/s, loss_g_model=-2.951, loss_d_model=0.324]\n",
      "[TRAIN] Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.71it/s, loss_g_model=-2.909, loss_d_model=0.319]\n",
      "[TRAIN] Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.80it/s, loss_g_model=-2.909, loss_d_model=0.379]\n",
      "[TRAIN] Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.71it/s, loss_g_model=-2.919, loss_d_model=0.399]\n",
      "[TRAIN] Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.86it/s, loss_g_model=-2.886, loss_d_model=0.462]\n",
      "[TRAIN] Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.80it/s, loss_g_model=-2.884, loss_d_model=0.561]\n",
      "[TRAIN] Epoch 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.54it/s, loss_g_model=-2.912, loss_d_model=0.487]\n",
      "[TRAIN] Epoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.61it/s, loss_g_model=-2.913, loss_d_model=0.360]\n",
      "[TRAIN] Epoch 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.65it/s, loss_g_model=-2.952, loss_d_model=0.626]\n",
      "[TRAIN] Epoch 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.75it/s, loss_g_model=-2.952, loss_d_model=0.497]\n",
      "[TRAIN] Epoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.84it/s, loss_g_model=-2.942, loss_d_model=0.546]\n",
      "[TRAIN] Epoch 16: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.49it/s, loss_g_model=-3.029, loss_d_model=0.658]\n",
      "[TRAIN] Epoch 17: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.52it/s, loss_g_model=-3.020, loss_d_model=0.723]\n",
      "[TRAIN] Epoch 18: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.67it/s, loss_g_model=-3.038, loss_d_model=0.592]\n",
      "[TRAIN] Epoch 19: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.73it/s, loss_g_model=-3.092, loss_d_model=0.692]\n",
      "[TRAIN] Epoch 20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.83it/s, loss_g_model=-3.149, loss_d_model=0.723]\n",
      "[TRAIN] Epoch 21: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.87it/s, loss_g_model=-3.140, loss_d_model=0.689]\n",
      "[TRAIN] Epoch 22: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.87it/s, loss_g_model=-3.192, loss_d_model=0.670]\n",
      "[TRAIN] Epoch 23: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.89it/s, loss_g_model=-3.221, loss_d_model=0.698]\n",
      "[TRAIN] Epoch 24: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.81it/s, loss_g_model=-3.231, loss_d_model=0.681]\n",
      "[TRAIN] Epoch 25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.80it/s, loss_g_model=-3.246, loss_d_model=0.713]\n",
      "[TRAIN] Epoch 26: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.77it/s, loss_g_model=-3.279, loss_d_model=0.738]\n",
      "[TRAIN] Epoch 27: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.88it/s, loss_g_model=-3.305, loss_d_model=0.718]\n",
      "[TRAIN] Epoch 28: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.84it/s, loss_g_model=-3.311, loss_d_model=0.619]\n",
      "[TRAIN] Epoch 29: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.90it/s, loss_g_model=-3.342, loss_d_model=0.623]\n",
      "[TRAIN] Epoch 30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.88it/s, loss_g_model=-3.332, loss_d_model=0.599]\n",
      "[TRAIN] Epoch 31: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.78it/s, loss_g_model=-3.387, loss_d_model=0.671]\n",
      "[TRAIN] Epoch 32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.73it/s, loss_g_model=-3.424, loss_d_model=0.681]\n",
      "[TRAIN] Epoch 33: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.80it/s, loss_g_model=-3.438, loss_d_model=0.623]\n",
      "[TRAIN] Epoch 34: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.87it/s, loss_g_model=-3.488, loss_d_model=0.636]\n",
      "[TRAIN] Epoch 35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.89it/s, loss_g_model=-3.465, loss_d_model=0.660]\n",
      "[TRAIN] Epoch 36: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.89it/s, loss_g_model=-3.494, loss_d_model=0.614]\n",
      "[TRAIN] Epoch 37: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.87it/s, loss_g_model=-3.501, loss_d_model=0.567]\n",
      "[TRAIN] Epoch 38: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.79it/s, loss_g_model=-3.479, loss_d_model=0.656]\n",
      "[TRAIN] Epoch 39: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.85it/s, loss_g_model=-3.541, loss_d_model=0.614]\n",
      "[TRAIN] Epoch 40: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.69it/s, loss_g_model=-3.610, loss_d_model=0.659]\n",
      "[TRAIN] Epoch 41: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.71it/s, loss_g_model=-3.600, loss_d_model=0.643]\n",
      "[TRAIN] Epoch 42: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.80it/s, loss_g_model=-3.634, loss_d_model=0.705]\n",
      "[TRAIN] Epoch 43: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.85it/s, loss_g_model=-3.677, loss_d_model=0.648]\n",
      "[TRAIN] Epoch 44: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.85it/s, loss_g_model=-3.629, loss_d_model=0.654]\n",
      "[TRAIN] Epoch 45: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.66it/s, loss_g_model=-3.637, loss_d_model=0.621]\n",
      "[TRAIN] Epoch 46: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.83it/s, loss_g_model=-3.655, loss_d_model=0.652]\n",
      "[TRAIN] Epoch 47: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.86it/s, loss_g_model=-3.610, loss_d_model=0.571]\n",
      "[TRAIN] Epoch 48: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.82it/s, loss_g_model=-3.643, loss_d_model=0.594]\n",
      "[TRAIN] Epoch 49: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.88it/s, loss_g_model=-3.673, loss_d_model=0.561]\n",
      "[TRAIN] Epoch 50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.83it/s, loss_g_model=-3.616, loss_d_model=0.630]\n",
      "[TRAIN] Epoch 51: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.79it/s, loss_g_model=-3.667, loss_d_model=0.653]\n",
      "[TRAIN] Epoch 52: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.70it/s, loss_g_model=-3.645, loss_d_model=0.663]\n",
      "[TRAIN] Epoch 53: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.84it/s, loss_g_model=-3.589, loss_d_model=0.619]\n",
      "[TRAIN] Epoch 54: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.87it/s, loss_g_model=-3.679, loss_d_model=0.601]\n",
      "[TRAIN] Epoch 55: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.80it/s, loss_g_model=-3.629, loss_d_model=0.630]\n",
      "[TRAIN] Epoch 56: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.86it/s, loss_g_model=-3.658, loss_d_model=0.706]\n",
      "[TRAIN] Epoch 57: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.86it/s, loss_g_model=-3.667, loss_d_model=0.663]\n",
      "[TRAIN] Epoch 58: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.68it/s, loss_g_model=-3.596, loss_d_model=0.545]\n",
      "[TRAIN] Epoch 59: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.76it/s, loss_g_model=-3.725, loss_d_model=0.621]\n",
      "[TRAIN] Epoch 60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.69it/s, loss_g_model=-3.696, loss_d_model=0.746]\n",
      "[TRAIN] Epoch 61: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.47it/s, loss_g_model=-3.732, loss_d_model=0.718]\n",
      "[TRAIN] Epoch 62: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.66it/s, loss_g_model=-3.747, loss_d_model=0.764]\n",
      "[TRAIN] Epoch 63: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.87it/s, loss_g_model=-3.745, loss_d_model=0.742]\n",
      "[TRAIN] Epoch 64: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.72it/s, loss_g_model=-3.779, loss_d_model=0.715]\n",
      "[TRAIN] Epoch 65: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.71it/s, loss_g_model=-3.770, loss_d_model=0.785]\n",
      "[TRAIN] Epoch 66: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.84it/s, loss_g_model=-3.817, loss_d_model=0.804]\n",
      "[TRAIN] Epoch 67: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.87it/s, loss_g_model=-3.843, loss_d_model=0.785]\n",
      "[TRAIN] Epoch 68: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.56it/s, loss_g_model=-3.853, loss_d_model=0.820]\n",
      "[TRAIN] Epoch 69: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.58it/s, loss_g_model=-3.881, loss_d_model=0.713]\n",
      "[TRAIN] Epoch 70: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.57it/s, loss_g_model=-3.831, loss_d_model=0.788]\n",
      "[TRAIN] Epoch 71: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.61it/s, loss_g_model=-3.781, loss_d_model=0.733]\n",
      "[TRAIN] Epoch 72: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.80it/s, loss_g_model=-3.807, loss_d_model=0.676]\n",
      "[TRAIN] Epoch 73: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.86it/s, loss_g_model=-3.788, loss_d_model=0.579]\n",
      "[TRAIN] Epoch 74: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.83it/s, loss_g_model=-3.724, loss_d_model=0.652]\n",
      "[TRAIN] Epoch 75: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.42it/s, loss_g_model=-3.758, loss_d_model=0.642]\n",
      "[TRAIN] Epoch 76: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.76it/s, loss_g_model=-3.730, loss_d_model=0.505]\n",
      "[TRAIN] Epoch 77: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.85it/s, loss_g_model=-3.713, loss_d_model=0.577]\n",
      "[TRAIN] Epoch 78: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.65it/s, loss_g_model=-3.810, loss_d_model=0.715]\n",
      "[TRAIN] Epoch 79: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.83it/s, loss_g_model=-3.688, loss_d_model=0.500]\n",
      "[TRAIN] Epoch 80: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.89it/s, loss_g_model=-3.741, loss_d_model=0.519]\n",
      "[TRAIN] Epoch 81: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.89it/s, loss_g_model=-3.740, loss_d_model=0.667]\n",
      "[TRAIN] Epoch 82: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.87it/s, loss_g_model=-3.744, loss_d_model=0.747]\n",
      "[TRAIN] Epoch 83: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.79it/s, loss_g_model=-3.720, loss_d_model=0.525]\n",
      "[TRAIN] Epoch 84: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.89it/s, loss_g_model=-3.812, loss_d_model=0.689]\n",
      "[TRAIN] Epoch 85: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.70it/s, loss_g_model=-3.805, loss_d_model=0.659]\n",
      "[TRAIN] Epoch 86: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.88it/s, loss_g_model=-3.779, loss_d_model=0.554]\n",
      "[TRAIN] Epoch 87: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.90it/s, loss_g_model=-3.828, loss_d_model=0.690]\n",
      "[TRAIN] Epoch 88: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.90it/s, loss_g_model=-3.775, loss_d_model=0.662]\n",
      "[TRAIN] Epoch 89: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.91it/s, loss_g_model=-3.745, loss_d_model=0.694]\n",
      "[TRAIN] Epoch 90: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.76it/s, loss_g_model=-3.764, loss_d_model=0.599]\n",
      "[TRAIN] Epoch 91: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.86it/s, loss_g_model=-3.807, loss_d_model=0.739]\n",
      "[TRAIN] Epoch 92: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.68it/s, loss_g_model=-3.720, loss_d_model=0.600]\n",
      "[TRAIN] Epoch 93: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.90it/s, loss_g_model=-3.819, loss_d_model=0.515]\n",
      "[TRAIN] Epoch 94: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.88it/s, loss_g_model=-3.813, loss_d_model=0.759]\n",
      "[TRAIN] Epoch 95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.87it/s, loss_g_model=-3.882, loss_d_model=0.591]\n",
      "[TRAIN] Epoch 96: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.90it/s, loss_g_model=-3.750, loss_d_model=0.692]\n",
      "[TRAIN] Epoch 97: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.70it/s, loss_g_model=-3.770, loss_d_model=0.625]\n",
      "[TRAIN] Epoch 98: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.78it/s, loss_g_model=-3.768, loss_d_model=0.518]\n",
      "[TRAIN] Epoch 99: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.75it/s, loss_g_model=-3.751, loss_d_model=0.784]\n",
      "[TRAIN] Epoch 100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.90it/s, loss_g_model=-3.811, loss_d_model=0.727]\n",
      "[TRAIN] Epoch 101: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.91it/s, loss_g_model=-3.778, loss_d_model=0.668]\n",
      "[TRAIN] Epoch 102: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.90it/s, loss_g_model=-3.826, loss_d_model=0.616]\n",
      "[TRAIN] Epoch 103: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.91it/s, loss_g_model=-3.806, loss_d_model=0.726]\n",
      "[TRAIN] Epoch 104: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.79it/s, loss_g_model=-3.715, loss_d_model=0.550]\n",
      "[TRAIN] Epoch 105: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.73it/s, loss_g_model=-3.788, loss_d_model=0.543]\n",
      "[TRAIN] Epoch 106: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.83it/s, loss_g_model=-3.714, loss_d_model=0.589]\n",
      "[TRAIN] Epoch 107: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.89it/s, loss_g_model=-3.790, loss_d_model=0.615]\n",
      "[TRAIN] Epoch 108: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.86it/s, loss_g_model=-3.808, loss_d_model=0.626]\n",
      "[TRAIN] Epoch 109: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.82it/s, loss_g_model=-3.758, loss_d_model=0.564]\n",
      "[TRAIN] Epoch 110: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.89it/s, loss_g_model=-3.754, loss_d_model=0.546]\n",
      "[TRAIN] Epoch 111: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.80it/s, loss_g_model=-3.709, loss_d_model=0.557]\n",
      "[TRAIN] Epoch 112: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.63it/s, loss_g_model=-3.796, loss_d_model=0.576]\n",
      "[TRAIN] Epoch 113: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.85it/s, loss_g_model=-3.684, loss_d_model=0.566]\n",
      "[TRAIN] Epoch 114: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.87it/s, loss_g_model=-3.716, loss_d_model=0.651]\n",
      "[TRAIN] Epoch 115: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.87it/s, loss_g_model=-3.680, loss_d_model=0.593]\n",
      "[TRAIN] Epoch 116: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.90it/s, loss_g_model=-3.697, loss_d_model=0.658]\n",
      "[TRAIN] Epoch 117: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.87it/s, loss_g_model=-3.688, loss_d_model=0.532]\n",
      "[TRAIN] Epoch 118: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.60it/s, loss_g_model=-3.675, loss_d_model=0.535]\n",
      "[TRAIN] Epoch 119: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.53it/s, loss_g_model=-3.660, loss_d_model=0.693]\n",
      "[TRAIN] Epoch 120: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.80it/s, loss_g_model=-3.681, loss_d_model=0.554]\n",
      "[TRAIN] Epoch 121: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.86it/s, loss_g_model=-3.818, loss_d_model=0.597]\n",
      "[TRAIN] Epoch 122: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.89it/s, loss_g_model=-3.694, loss_d_model=0.683]\n",
      "[TRAIN] Epoch 123: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.90it/s, loss_g_model=-3.745, loss_d_model=0.712]\n",
      "[TRAIN] Epoch 124: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.89it/s, loss_g_model=-3.766, loss_d_model=0.647]\n",
      "[TRAIN] Epoch 125: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.76it/s, loss_g_model=-3.871, loss_d_model=0.586]\n",
      "[TRAIN] Epoch 126: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.49it/s, loss_g_model=-3.767, loss_d_model=0.558]\n",
      "[TRAIN] Epoch 127: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.68it/s, loss_g_model=-3.797, loss_d_model=0.658]\n",
      "[TRAIN] Epoch 128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.76it/s, loss_g_model=-3.818, loss_d_model=0.625]\n",
      "[TRAIN] Epoch 129: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.50it/s, loss_g_model=-3.692, loss_d_model=0.605]\n",
      "[TRAIN] Epoch 130: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.65it/s, loss_g_model=-3.696, loss_d_model=0.555]\n",
      "[TRAIN] Epoch 131: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.54it/s, loss_g_model=-3.720, loss_d_model=0.431]\n",
      "[TRAIN] Epoch 132: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.65it/s, loss_g_model=-3.629, loss_d_model=0.682]\n",
      "[TRAIN] Epoch 133: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.50it/s, loss_g_model=-3.769, loss_d_model=0.633]\n",
      "[TRAIN] Epoch 134: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.78it/s, loss_g_model=-3.654, loss_d_model=0.608]\n",
      "[TRAIN] Epoch 135: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.82it/s, loss_g_model=-3.708, loss_d_model=0.365]\n",
      "[TRAIN] Epoch 136: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.86it/s, loss_g_model=-3.694, loss_d_model=0.477]\n",
      "[TRAIN] Epoch 137: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.87it/s, loss_g_model=-3.660, loss_d_model=0.478]\n",
      "[TRAIN] Epoch 138: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.80it/s, loss_g_model=-3.669, loss_d_model=0.497]\n",
      "[TRAIN] Epoch 139: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.68it/s, loss_g_model=-3.707, loss_d_model=0.343]\n",
      "[TRAIN] Epoch 140: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.61it/s, loss_g_model=-3.573, loss_d_model=0.410]\n",
      "[TRAIN] Epoch 141: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.86it/s, loss_g_model=-3.661, loss_d_model=0.400]\n",
      "[TRAIN] Epoch 142: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.74it/s, loss_g_model=-3.629, loss_d_model=0.429]\n",
      "[TRAIN] Epoch 143: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.85it/s, loss_g_model=-3.711, loss_d_model=0.476]\n",
      "[TRAIN] Epoch 144: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.86it/s, loss_g_model=-3.698, loss_d_model=0.446]\n",
      "[TRAIN] Epoch 145: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.78it/s, loss_g_model=-3.733, loss_d_model=0.314]\n",
      "[TRAIN] Epoch 146: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.84it/s, loss_g_model=-3.646, loss_d_model=0.432]\n",
      "[TRAIN] Epoch 147: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.71it/s, loss_g_model=-3.678, loss_d_model=0.358]\n",
      "[TRAIN] Epoch 148: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.87it/s, loss_g_model=-3.694, loss_d_model=0.328]\n",
      "[TRAIN] Epoch 149: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.87it/s, loss_g_model=-3.639, loss_d_model=0.356]\n",
      "[TRAIN] Epoch 150: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.88it/s, loss_g_model=-3.666, loss_d_model=0.431]\n",
      "[TRAIN] Epoch 151: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.88it/s, loss_g_model=-3.718, loss_d_model=0.438]\n",
      "[TRAIN] Epoch 152: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.65it/s, loss_g_model=-3.652, loss_d_model=0.381]\n",
      "[TRAIN] Epoch 153: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.84it/s, loss_g_model=-3.747, loss_d_model=0.391]\n",
      "[TRAIN] Epoch 154: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.76it/s, loss_g_model=-3.718, loss_d_model=0.322]\n",
      "[TRAIN] Epoch 155: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.86it/s, loss_g_model=-3.590, loss_d_model=0.372]\n",
      "[TRAIN] Epoch 156: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.87it/s, loss_g_model=-3.652, loss_d_model=0.391]\n",
      "[TRAIN] Epoch 157: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.89it/s, loss_g_model=-3.672, loss_d_model=0.512]\n",
      "[TRAIN] Epoch 158: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.86it/s, loss_g_model=-3.720, loss_d_model=0.432]\n",
      "[TRAIN] Epoch 159: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.59it/s, loss_g_model=-3.701, loss_d_model=0.425]\n",
      "[TRAIN] Epoch 160: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.87it/s, loss_g_model=-3.652, loss_d_model=0.398]\n",
      "[TRAIN] Epoch 161: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.78it/s, loss_g_model=-3.801, loss_d_model=0.516]\n",
      "[TRAIN] Epoch 162: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.84it/s, loss_g_model=-3.639, loss_d_model=0.422]\n",
      "[TRAIN] Epoch 163: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.88it/s, loss_g_model=-3.613, loss_d_model=0.364]\n",
      "[TRAIN] Epoch 164: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.86it/s, loss_g_model=-3.602, loss_d_model=0.389]\n",
      "[TRAIN] Epoch 165: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.79it/s, loss_g_model=-3.579, loss_d_model=0.529]\n",
      "[TRAIN] Epoch 166: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.81it/s, loss_g_model=-3.705, loss_d_model=0.296]\n",
      "[TRAIN] Epoch 167: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.84it/s, loss_g_model=-3.612, loss_d_model=0.425]\n",
      "[TRAIN] Epoch 168: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.73it/s, loss_g_model=-3.607, loss_d_model=0.451]\n",
      "[TRAIN] Epoch 169: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.84it/s, loss_g_model=-3.598, loss_d_model=0.408]\n",
      "[TRAIN] Epoch 170: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.88it/s, loss_g_model=-3.566, loss_d_model=0.282]\n",
      "[TRAIN] Epoch 171: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.85it/s, loss_g_model=-3.698, loss_d_model=0.338]\n",
      "[TRAIN] Epoch 172: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.72it/s, loss_g_model=-3.669, loss_d_model=0.369]\n",
      "[TRAIN] Epoch 173: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.77it/s, loss_g_model=-3.569, loss_d_model=0.393]\n",
      "[TRAIN] Epoch 174: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.83it/s, loss_g_model=-3.669, loss_d_model=0.279]\n",
      "[TRAIN] Epoch 175: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.67it/s, loss_g_model=-3.579, loss_d_model=0.305]\n",
      "[TRAIN] Epoch 176: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.51it/s, loss_g_model=-3.594, loss_d_model=0.224]\n",
      "[TRAIN] Epoch 177: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.57it/s, loss_g_model=-3.631, loss_d_model=0.265]\n",
      "[TRAIN] Epoch 178: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.60it/s, loss_g_model=-3.619, loss_d_model=0.259]\n",
      "[TRAIN] Epoch 179: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.39it/s, loss_g_model=-3.568, loss_d_model=0.248]\n",
      "[TRAIN] Epoch 180: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.69it/s, loss_g_model=-3.674, loss_d_model=0.342]\n",
      "[TRAIN] Epoch 181: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.83it/s, loss_g_model=-3.565, loss_d_model=0.101]\n",
      "[TRAIN] Epoch 182: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.81it/s, loss_g_model=-3.476, loss_d_model=0.065]\n",
      "[TRAIN] Epoch 183: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.76it/s, loss_g_model=-3.572, loss_d_model=0.202]\n",
      "[TRAIN] Epoch 184: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.43it/s, loss_g_model=-3.652, loss_d_model=0.062]\n",
      "[TRAIN] Epoch 185: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.39it/s, loss_g_model=-3.608, loss_d_model=0.058]\n",
      "[TRAIN] Epoch 186: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.61it/s, loss_g_model=-3.539, loss_d_model=0.125]\n",
      "[TRAIN] Epoch 187: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.49it/s, loss_g_model=-3.565, loss_d_model=0.207]\n",
      "[TRAIN] Epoch 188: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.54it/s, loss_g_model=-3.708, loss_d_model=0.034]\n",
      "[TRAIN] Epoch 189: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.50it/s, loss_g_model=-3.614, loss_d_model=0.041]\n",
      "[TRAIN] Epoch 190: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.36it/s, loss_g_model=-3.590, loss_d_model=0.175]\n",
      "[TRAIN] Epoch 191: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.40it/s, loss_g_model=-3.631, loss_d_model=0.056]\n",
      "[TRAIN] Epoch 192: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.55it/s, loss_g_model=-3.512, loss_d_model=0.201]\n",
      "[TRAIN] Epoch 193: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.79it/s, loss_g_model=-3.616, loss_d_model=0.318]\n",
      "[TRAIN] Epoch 194: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.56it/s, loss_g_model=-3.572, loss_d_model=0.100]\n",
      "[TRAIN] Epoch 195: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.75it/s, loss_g_model=-3.608, loss_d_model=0.232]\n",
      "[TRAIN] Epoch 196: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.73it/s, loss_g_model=-3.568, loss_d_model=0.101]\n",
      "[TRAIN] Epoch 197: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.82it/s, loss_g_model=-3.607, loss_d_model=0.116]\n",
      "[TRAIN] Epoch 198: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.81it/s, loss_g_model=-3.734, loss_d_model=0.177]\n",
      "[TRAIN] Epoch 199: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.82it/s, loss_g_model=-3.704, loss_d_model=0.184]\n",
      "[TRAIN] Epoch 200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.84it/s, loss_g_model=-3.606, loss_d_model=0.111]\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(g_model,\n",
    "                  d_model,\n",
    "                  trainer_kwargs={'max_epochs': 200})\n",
    "trainer.fit()\n",
    "trainer.save('./parameters/' + 'cross_validation_proposed_pretrain.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "law",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
